{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import json\n",
        "import random\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "from dataclasses import dataclass\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def setup_gemini(api_key: str = None):\n",
        "    if api_key is None:\n",
        "        api_key = input(\"Enter your Gemini API key: \").strip()\n",
        "    genai.configure(api_key=api_key)\n",
        "    model = genai.GenerativeModel('gemini-2.0-flash-exp')\n",
        "    print(\"✓ Gemini 2.0 Flash configured\")\n",
        "    return model\n",
        "\n",
        "@dataclass\n",
        "class Example:\n",
        "    text: str\n",
        "    sentiment: str\n",
        "    def to_dict(self):\n",
        "        return {\"text\": self.text, \"sentiment\": self.sentiment}\n",
        "\n",
        "@dataclass\n",
        "class Prediction:\n",
        "    sentiment: str\n",
        "    reasoning: str = \"\"\n",
        "    confidence: float = 1.0"
      ],
      "metadata": {
        "id": "oMe4tpzFujNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset() -> Tuple[List[Example], List[Example]]:\n",
        "    train_data = [\n",
        "        Example(\"This movie was absolutely fantastic! Best film of the year.\", \"positive\"),\n",
        "        Example(\"Terrible experience, waste of time and money.\", \"negative\"),\n",
        "        Example(\"The product works as expected, nothing special.\", \"neutral\"),\n",
        "        Example(\"I'm blown away by the quality and attention to detail!\", \"positive\"),\n",
        "        Example(\"Disappointing and overpriced. Would not recommend.\", \"negative\"),\n",
        "        Example(\"It's okay, does the job but could be better.\", \"neutral\"),\n",
        "        Example(\"Incredible customer service and amazing results!\", \"positive\"),\n",
        "        Example(\"Complete garbage, broke after one use.\", \"negative\"),\n",
        "        Example(\"Average product, met my basic expectations.\", \"neutral\"),\n",
        "        Example(\"Revolutionary! This changed everything for me.\", \"positive\"),\n",
        "        Example(\"Frustrating bugs and poor design choices.\", \"negative\"),\n",
        "        Example(\"Decent quality for the price point.\", \"neutral\"),\n",
        "        Example(\"Exceeded all my expectations, truly remarkable!\", \"positive\"),\n",
        "        Example(\"Worst purchase I've ever made, avoid at all costs.\", \"negative\"),\n",
        "        Example(\"It's fine, nothing to complain about really.\", \"neutral\"),\n",
        "        Example(\"Absolutely stellar performance, 5 stars!\", \"positive\"),\n",
        "        Example(\"Broken and unusable, total disaster.\", \"negative\"),\n",
        "        Example(\"Meets requirements, standard quality.\", \"neutral\"),\n",
        "    ]\n",
        "    val_data = [\n",
        "        Example(\"Absolutely love it, couldn't be happier!\", \"positive\"),\n",
        "        Example(\"Broken on arrival, very upset.\", \"negative\"),\n",
        "        Example(\"Works fine, no major issues.\", \"neutral\"),\n",
        "        Example(\"Outstanding performance and great value!\", \"positive\"),\n",
        "        Example(\"Regret buying this, total letdown.\", \"negative\"),\n",
        "        Example(\"Adequate for basic use.\", \"neutral\"),\n",
        "    ]\n",
        "    return train_data, val_data\n",
        "\n",
        "class PromptTemplate:\n",
        "    def __init__(self, instruction: str = \"\", examples: List[Example] = None):\n",
        "        self.instruction = instruction\n",
        "        self.examples = examples or []\n",
        "    def format(self, text: str) -> str:\n",
        "        prompt_parts = []\n",
        "        if self.instruction:\n",
        "            prompt_parts.append(self.instruction)\n",
        "        if self.examples:\n",
        "            prompt_parts.append(\"\\nExamples:\")\n",
        "            for ex in self.examples:\n",
        "                prompt_parts.append(f\"\\nText: {ex.text}\")\n",
        "                prompt_parts.append(f\"Sentiment: {ex.sentiment}\")\n",
        "        prompt_parts.append(f\"\\nText: {text}\")\n",
        "        prompt_parts.append(\"Sentiment:\")\n",
        "        return \"\\n\".join(prompt_parts)\n",
        "    def clone(self):\n",
        "        return PromptTemplate(self.instruction, self.examples.copy())"
      ],
      "metadata": {
        "id": "7ISz0W7nujDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentModel:\n",
        "    def __init__(self, model, prompt_template: PromptTemplate):\n",
        "        self.model = model\n",
        "        self.prompt_template = prompt_template\n",
        "\n",
        "    def predict(self, text: str) -> Prediction:\n",
        "        prompt = self.prompt_template.format(text)\n",
        "        try:\n",
        "            response = self.model.generate_content(prompt)\n",
        "            result = response.text.strip().lower()\n",
        "            for sentiment in ['positive', 'negative', 'neutral']:\n",
        "                if sentiment in result:\n",
        "                    return Prediction(sentiment=sentiment, reasoning=result)\n",
        "            return Prediction(sentiment='neutral', reasoning=result)\n",
        "        except Exception as e:\n",
        "            return Prediction(sentiment='neutral', reasoning=str(e))\n",
        "\n",
        "    def evaluate(self, dataset: List[Example]) -> float:\n",
        "        correct = 0\n",
        "        for example in dataset:\n",
        "            pred = self.predict(example.text)\n",
        "            if pred.sentiment == example.sentiment:\n",
        "                correct += 1\n",
        "        return (correct / len(dataset)) * 100"
      ],
      "metadata": {
        "id": "j20-94tQui4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PromptOptimizer:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.instruction_candidates = [\n",
        "            \"Analyze the sentiment of the following text. Classify as positive, negative, or neutral.\",\n",
        "            \"Classify the sentiment: positive, negative, or neutral.\",\n",
        "            \"Determine if this text expresses positive, negative, or neutral sentiment.\",\n",
        "            \"What is the emotional tone? Answer: positive, negative, or neutral.\",\n",
        "            \"Sentiment classification (positive/negative/neutral):\",\n",
        "            \"Evaluate sentiment and respond with exactly one word: positive, negative, or neutral.\",\n",
        "        ]\n",
        "\n",
        "    def select_best_examples(self, train_data: List[Example], val_data: List[Example], n_examples: int = 3) -> List[Example]:\n",
        "        best_examples = None\n",
        "        best_score = 0\n",
        "        for _ in range(10):\n",
        "            examples_by_sentiment = {\n",
        "                'positive': [e for e in train_data if e.sentiment == 'positive'],\n",
        "                'negative': [e for e in train_data if e.sentiment == 'negative'],\n",
        "                'neutral': [e for e in train_data if e.sentiment == 'neutral']\n",
        "            }\n",
        "            selected = []\n",
        "            for sentiment in ['positive', 'negative', 'neutral']:\n",
        "                if examples_by_sentiment[sentiment]:\n",
        "                    selected.append(random.choice(examples_by_sentiment[sentiment]))\n",
        "            remaining = [e for e in train_data if e not in selected]\n",
        "            while len(selected) < n_examples and remaining:\n",
        "                selected.append(random.choice(remaining))\n",
        "                remaining.remove(selected[-1])\n",
        "            template = PromptTemplate(instruction=self.instruction_candidates[0], examples=selected)\n",
        "            test_model = SentimentModel(self.model, template)\n",
        "            score = test_model.evaluate(val_data[:3])\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_examples = selected\n",
        "        return best_examples\n",
        "\n",
        "    def optimize_instruction(self, examples: List[Example], val_data: List[Example]) -> str:\n",
        "        best_instruction = self.instruction_candidates[0]\n",
        "        best_score = 0\n",
        "        for instruction in self.instruction_candidates:\n",
        "            template = PromptTemplate(instruction=instruction, examples=examples)\n",
        "            test_model = SentimentModel(self.model, template)\n",
        "            score = test_model.evaluate(val_data)\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_instruction = instruction\n",
        "        return best_instruction"
      ],
      "metadata": {
        "id": "Ag2lDjZPui1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def compile(self, train_data: List[Example], val_data: List[Example], n_examples: int = 3) -> PromptTemplate:\n",
        "        best_examples = self.select_best_examples(train_data, val_data, n_examples)\n",
        "        best_instruction = self.optimize_instruction(best_examples, val_data)\n",
        "        optimized_template = PromptTemplate(instruction=best_instruction, examples=best_examples)\n",
        "        return optimized_template\n",
        "\n",
        "def main():\n",
        "    print(\"=\"*70)\n",
        "    print(\"Prompt Optimization Tutorial\")\n",
        "    print(\"Stop Writing Prompts, Start Programming Them!\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    model = setup_gemini()\n",
        "    train_data, val_data = create_dataset()\n",
        "    print(f\"✓ {len(train_data)} training examples, {len(val_data)} validation examples\")\n",
        "\n",
        "    baseline_template = PromptTemplate(\n",
        "        instruction=\"Classify sentiment as positive, negative, or neutral.\",\n",
        "        examples=[]\n",
        "    )\n",
        "    baseline_model = SentimentModel(model, baseline_template)\n",
        "    baseline_score = baseline_model.evaluate(val_data)\n",
        "\n",
        "    manual_examples = train_data[:3]\n",
        "    manual_template = PromptTemplate(\n",
        "        instruction=\"Classify sentiment as positive, negative, or neutral.\",\n",
        "        examples=manual_examples\n",
        "    )\n",
        "    manual_model = SentimentModel(model, manual_template)\n",
        "    manual_score = manual_model.evaluate(val_data)\n",
        "\n",
        "    optimizer = PromptOptimizer(model)\n",
        "    optimized_template = optimizer.compile(train_data, val_data, n_examples=4)"
      ],
      "metadata": {
        "id": "PcvUnDh9uiyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    optimized_model = SentimentModel(model, optimized_template)\n",
        "    optimized_score = optimized_model.evaluate(val_data)\n",
        "\n",
        "    print(f\"Baseline (zero-shot):     {baseline_score:.1f}%\")\n",
        "    print(f\"Manual few-shot:          {manual_score:.1f}%\")\n",
        "    print(f\"Optimized (compiled):     {optimized_score:.1f}%\")\n",
        "\n",
        "    print(f\"\\nInstruction: {optimized_template.instruction}\")\n",
        "    print(f\"\\nSelected Examples ({len(optimized_template.examples)}):\")\n",
        "    for i, ex in enumerate(optimized_template.examples, 1):\n",
        "        print(f\"\\n{i}. Text: {ex.text}\")\n",
        "        print(f\"   Sentiment: {ex.sentiment}\")\n",
        "\n",
        "    test_cases = [\n",
        "        \"This is absolutely amazing, I love it!\",\n",
        "        \"Completely broken and unusable.\",\n",
        "        \"It works as advertised, no complaints.\"\n",
        "    ]\n",
        "\n",
        "    for test_text in test_cases:\n",
        "        print(f\"\\nInput: {test_text}\")\n",
        "        pred = optimized_model.predict(test_text)\n",
        "        print(f\"Predicted: {pred.sentiment}\")\n",
        "\n",
        "    print(\"✓ Tutorial Complete!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "2z-7In9qulS7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}