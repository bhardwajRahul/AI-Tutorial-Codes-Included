{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os, math, random, time\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple\n",
        "import subprocess, sys\n",
        "\n",
        "def pip_install(pkgs):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + pkgs)\n",
        "\n",
        "pip_install([\"torch\", \"torchvision\", \"numpy\", \"matplotlib\", \"networkx\", \"tqdm\"])\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "from tqdm import trange\n",
        "\n",
        "SEED = 7\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = False\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "train_ds = datasets.MNIST(root=\"/content/data\", train=True, download=True, transform=transform)\n",
        "test_ds  = datasets.MNIST(root=\"/content/data\", train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "jShaNPKrKrR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_noniid_clients(dataset, num_clients=20, shards_per_client=2, seed=SEED):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    y = np.array([dataset[i][1] for i in range(len(dataset))])\n",
        "    idx = np.arange(len(dataset))\n",
        "    idx_sorted = idx[np.argsort(y)]\n",
        "    num_shards = num_clients * shards_per_client\n",
        "    shard_size = len(dataset) // num_shards\n",
        "    shards = [idx_sorted[i*shard_size:(i+1)*shard_size] for i in range(num_shards)]\n",
        "    rng.shuffle(shards)\n",
        "    client_indices = []\n",
        "    for c in range(num_clients):\n",
        "        take = shards[c*shards_per_client:(c+1)*shards_per_client]\n",
        "        client_indices.append(np.concatenate(take))\n",
        "    return client_indices\n",
        "\n",
        "NUM_CLIENTS = 20\n",
        "client_indices = make_noniid_clients(train_ds, num_clients=NUM_CLIENTS, shards_per_client=2)\n",
        "\n",
        "test_loader = DataLoader(test_ds, batch_size=1024, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)"
      ],
      "metadata": {
        "id": "ZiY1TZRzKq3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_params(model):\n",
        "    return {k: v.detach().clone() for k, v in model.state_dict().items()}\n",
        "\n",
        "def set_model_params(model, params):\n",
        "    model.load_state_dict(params, strict=True)\n",
        "\n",
        "def add_params(a, b):\n",
        "    return {k: a[k] + b[k] for k in a.keys()}\n",
        "\n",
        "def sub_params(a, b):\n",
        "    return {k: a[k] - b[k] for k in a.keys()}\n",
        "\n",
        "def scale_params(a, s):\n",
        "    return {k: a[k] * s for k in a.keys()}\n",
        "\n",
        "def mean_params(params_list):\n",
        "    out = {k: torch.zeros_like(params_list[0][k]) for k in params_list[0].keys()}\n",
        "    for p in params_list:\n",
        "        for k in out.keys():\n",
        "            out[k] += p[k]\n",
        "    for k in out.keys():\n",
        "        out[k] /= len(params_list)\n",
        "    return out\n",
        "\n",
        "def l2_norm_params(delta):\n",
        "    sq = 0.0\n",
        "    for v in delta.values():\n",
        "        sq += float(torch.sum(v.float() * v.float()).item())\n",
        "    return math.sqrt(sq)\n",
        "\n",
        "def dp_sanitize_update(delta, clip_norm, epsilon, delta_dp, rng):\n",
        "    norm = l2_norm_params(delta)\n",
        "    scale = min(1.0, clip_norm / (norm + 1e-12))\n",
        "    clipped = scale_params(delta, scale)\n",
        "    if epsilon is None or math.isinf(epsilon) or epsilon <= 0:\n",
        "        return clipped\n",
        "    sigma = clip_norm * math.sqrt(2.0 * math.log(1.25 / delta_dp)) / epsilon\n",
        "    noised = {}\n",
        "    for k, v in clipped.items():\n",
        "        noise = torch.normal(mean=0.0, std=sigma, size=v.shape, generator=rng, device=v.device, dtype=v.dtype)\n",
        "        noised[k] = v + noise\n",
        "    return noised"
      ],
      "metadata": {
        "id": "nmqiVdCUKqsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def local_train_one_client(base_params, client_id, epochs, lr, batch_size, weight_decay=0.0):\n",
        "    model = MLP().to(device)\n",
        "    set_model_params(model, base_params)\n",
        "    model.train()\n",
        "    loader = DataLoader(\n",
        "        Subset(train_ds, client_indices[client_id].tolist() if hasattr(client_indices[client_id], \"tolist\") else client_indices[client_id]),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    opt = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
        "    for _ in range(epochs):\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            logits = model(xb)\n",
        "            loss = F.cross_entropy(logits, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "    return get_model_params(model)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(params):\n",
        "    model = MLP().to(device)\n",
        "    set_model_params(model, params)\n",
        "    model.eval()\n",
        "    total, correct = 0, 0\n",
        "    loss_sum = 0.0\n",
        "    for xb, yb in test_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logits = model(xb)\n",
        "        loss = F.cross_entropy(logits, yb, reduction=\"sum\")\n",
        "        loss_sum += float(loss.item())\n",
        "        pred = torch.argmax(logits, dim=1)\n",
        "        correct += int((pred == yb).sum().item())\n",
        "        total += int(yb.numel())\n",
        "    return loss_sum / total, correct / total"
      ],
      "metadata": {
        "id": "dPhbishhKqqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class FedAvgConfig:\n",
        "    rounds: int = 25\n",
        "    clients_per_round: int = 10\n",
        "    local_epochs: int = 1\n",
        "    lr: float = 0.06\n",
        "    batch_size: int = 64\n",
        "    clip_norm: float = 2.0\n",
        "    epsilon: float = math.inf\n",
        "    delta_dp: float = 1e-5\n",
        "\n",
        "def run_fedavg(cfg):\n",
        "    global_params = get_model_params(MLP().to(device))\n",
        "    history = {\"test_loss\": [], \"test_acc\": []}\n",
        "    for r in trange(cfg.rounds):\n",
        "        chosen = random.sample(range(NUM_CLIENTS), k=cfg.clients_per_round)\n",
        "        start_params = global_params\n",
        "        updates = []\n",
        "        for cid in chosen:\n",
        "            local_params = local_train_one_client(start_params, cid, cfg.local_epochs, cfg.lr, cfg.batch_size)\n",
        "            delta = sub_params(local_params, start_params)\n",
        "            rng = torch.Generator(device=device)\n",
        "            rng.manual_seed(SEED * 10000 + r * 100 + cid)\n",
        "            delta_dp = dp_sanitize_update(delta, cfg.clip_norm, cfg.epsilon, cfg.delta_dp, rng)\n",
        "            updates.append(delta_dp)\n",
        "        avg_update = mean_params(updates)\n",
        "        global_params = add_params(start_params, avg_update)\n",
        "        tl, ta = evaluate(global_params)\n",
        "        history[\"test_loss\"].append(tl)\n",
        "        history[\"test_acc\"].append(ta)\n",
        "    return history, global_params"
      ],
      "metadata": {
        "id": "EjDLO918KqnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class GossipConfig:\n",
        "    rounds: int = 25\n",
        "    local_epochs: int = 1\n",
        "    lr: float = 0.06\n",
        "    batch_size: int = 64\n",
        "    clip_norm: float = 2.0\n",
        "    epsilon: float = math.inf\n",
        "    delta_dp: float = 1e-5\n",
        "    topology: str = \"ring\"\n",
        "    p: float = 0.2\n",
        "    gossip_pairs_per_round: int = 10\n",
        "\n",
        "def build_topology(cfg):\n",
        "    if cfg.topology == \"ring\":\n",
        "        G = nx.cycle_graph(NUM_CLIENTS)\n",
        "    elif cfg.topology == \"erdos_renyi\":\n",
        "        G = nx.erdos_renyi_graph(NUM_CLIENTS, cfg.p, seed=SEED)\n",
        "        if not nx.is_connected(G):\n",
        "            comps = list(nx.connected_components(G))\n",
        "            for i in range(len(comps) - 1):\n",
        "                a = next(iter(comps[i]))\n",
        "                b = next(iter(comps[i+1]))\n",
        "                G.add_edge(a, b)\n",
        "    else:\n",
        "        raise ValueError\n",
        "    return G\n",
        "\n",
        "def run_gossip(cfg):\n",
        "    node_params = [get_model_params(MLP().to(device)) for _ in range(NUM_CLIENTS)]\n",
        "    G = build_topology(cfg)\n",
        "    history = {\"avg_test_loss\": [], \"avg_test_acc\": []}\n",
        "    for r in trange(cfg.rounds):\n",
        "        new_params = []\n",
        "        for cid in range(NUM_CLIENTS):\n",
        "            p0 = node_params[cid]\n",
        "            p_local = local_train_one_client(p0, cid, cfg.local_epochs, cfg.lr, cfg.batch_size)\n",
        "            delta = sub_params(p_local, p0)\n",
        "            rng = torch.Generator(device=device)\n",
        "            rng.manual_seed(SEED * 10000 + r * 100 + cid)\n",
        "            delta_dp = dp_sanitize_update(delta, cfg.clip_norm, cfg.epsilon, cfg.delta_dp, rng)\n",
        "            p_local_dp = add_params(p0, delta_dp)\n",
        "            new_params.append(p_local_dp)\n",
        "        node_params = new_params\n",
        "        edges = list(G.edges())\n",
        "        for _ in range(cfg.gossip_pairs_per_round):\n",
        "            i, j = random.choice(edges)\n",
        "            avg = mean_params([node_params[i], node_params[j]])\n",
        "            node_params[i] = avg\n",
        "            node_params[j] = avg\n",
        "        losses, accs = [], []\n",
        "        for cid in range(NUM_CLIENTS):\n",
        "            tl, ta = evaluate(node_params[cid])\n",
        "            losses.append(tl)\n",
        "            accs.append(ta)\n",
        "        history[\"avg_test_loss\"].append(float(np.mean(losses)))\n",
        "        history[\"avg_test_acc\"].append(float(np.mean(accs)))\n",
        "    return history, node_params"
      ],
      "metadata": {
        "id": "HO4G4gERKqkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AmVZs3Mu2uT",
        "outputId": "a94dc3f6-184e-4a8e-ed2f-e5df5c8d92cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 30.3MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.13MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 9.73MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.49MB/s]\n",
            "FedAvg (eps=inf):   0%|          | 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "FedAvg (eps=inf): 100%|██████████| 20/20 [02:35<00:00,  7.80s/it]\n",
            "Gossip (eps=inf, topo=ring): 100%|██████████| 20/20 [13:07<00:00, 39.37s/it]\n",
            "FedAvg (eps=8.0):  25%|██▌       | 5/20 [00:39<01:57,  7.81s/it]"
          ]
        }
      ],
      "source": [
        "eps_sweep = [math.inf, 8.0, 4.0, 2.0, 1.0]\n",
        "ROUNDS = 20\n",
        "\n",
        "fedavg_results = {}\n",
        "gossip_results = {}\n",
        "\n",
        "common_local_epochs = 1\n",
        "common_lr = 0.06\n",
        "common_bs = 64\n",
        "common_clip = 2.0\n",
        "common_delta = 1e-5\n",
        "\n",
        "for eps in eps_sweep:\n",
        "    fcfg = FedAvgConfig(\n",
        "        rounds=ROUNDS,\n",
        "        clients_per_round=10,\n",
        "        local_epochs=common_local_epochs,\n",
        "        lr=common_lr,\n",
        "        batch_size=common_bs,\n",
        "        clip_norm=common_clip,\n",
        "        epsilon=eps,\n",
        "        delta_dp=common_delta\n",
        "    )\n",
        "    hist_f, _ = run_fedavg(fcfg)\n",
        "    fedavg_results[eps] = hist_f\n",
        "\n",
        "    gcfg = GossipConfig(\n",
        "        rounds=ROUNDS,\n",
        "        local_epochs=common_local_epochs,\n",
        "        lr=common_lr,\n",
        "        batch_size=common_bs,\n",
        "        clip_norm=common_clip,\n",
        "        epsilon=eps,\n",
        "        delta_dp=common_delta,\n",
        "        topology=\"ring\",\n",
        "        gossip_pairs_per_round=10\n",
        "    )\n",
        "    hist_g, _ = run_gossip(gcfg)\n",
        "    gossip_results[eps] = hist_g\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "for eps in eps_sweep:\n",
        "    plt.plot(fedavg_results[eps][\"test_acc\"], label=f\"FedAvg eps={eps}\")\n",
        "plt.xlabel(\"Round\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "for eps in eps_sweep:\n",
        "    plt.plot(gossip_results[eps][\"avg_test_acc\"], label=f\"Gossip eps={eps}\")\n",
        "plt.xlabel(\"Round\")\n",
        "plt.ylabel(\"Avg Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "final_fed = [fedavg_results[eps][\"test_acc\"][-1] for eps in eps_sweep]\n",
        "final_gos = [gossip_results[eps][\"avg_test_acc\"][-1] for eps in eps_sweep]\n",
        "\n",
        "x = [100.0 if math.isinf(eps) else eps for eps in eps_sweep]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(x, final_fed, marker=\"o\", label=\"FedAvg\")\n",
        "plt.plot(x, final_gos, marker=\"o\", label=\"Gossip\")\n",
        "plt.xlabel(\"Epsilon\")\n",
        "plt.ylabel(\"Final Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "def rounds_to_threshold(acc_curve, threshold):\n",
        "    for i, a in enumerate(acc_curve):\n",
        "        if a >= threshold:\n",
        "            return i + 1\n",
        "    return None\n",
        "\n",
        "best_f = fedavg_results[math.inf][\"test_acc\"][-1]\n",
        "best_g = gossip_results[math.inf][\"avg_test_acc\"][-1]\n",
        "\n",
        "th_f = 0.9 * best_f\n",
        "th_g = 0.9 * best_g\n",
        "\n",
        "for eps in eps_sweep:\n",
        "    rf = rounds_to_threshold(fedavg_results[eps][\"test_acc\"], th_f)\n",
        "    rg = rounds_to_threshold(gossip_results[eps][\"avg_test_acc\"], th_g)\n",
        "    print(eps, rf, rg)"
      ]
    }
  ]
}