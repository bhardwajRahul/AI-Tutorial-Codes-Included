{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import asyncio, random, time, math, statistics\n",
        "from dataclasses import dataclass, field\n",
        "from collections import deque\n",
        "\n",
        "def now_ms():\n",
        "    return time.perf_counter() * 1000.0\n",
        "\n",
        "def pctl(xs, p):\n",
        "    if not xs:\n",
        "        return None\n",
        "    xs2 = sorted(xs)\n",
        "    k = (len(xs2) - 1) * p\n",
        "    f = math.floor(k)\n",
        "    c = math.ceil(k)\n",
        "    if f == c:\n",
        "        return xs2[int(k)]\n",
        "    return xs2[f] + (xs2[c] - xs2[f]) * (k - f)\n",
        "\n",
        "@dataclass\n",
        "class Stats:\n",
        "    latencies_ms: list = field(default_factory=list)\n",
        "    ok: int = 0\n",
        "    fail: int = 0\n",
        "    dropped: int = 0\n",
        "    retries: int = 0\n",
        "    timeouts: int = 0\n",
        "    cb_open: int = 0\n",
        "    dlq: int = 0\n",
        "\n",
        "    def summary(self, name):\n",
        "        l = self.latencies_ms\n",
        "        return {\n",
        "            \"name\": name,\n",
        "            \"ok\": self.ok,\n",
        "            \"fail\": self.fail,\n",
        "            \"dropped\": self.dropped,\n",
        "            \"retries\": self.retries,\n",
        "            \"timeouts\": self.timeouts,\n",
        "            \"cb_open\": self.cb_open,\n",
        "            \"dlq\": self.dlq,\n",
        "            \"lat_p50_ms\": round(pctl(l, 0.50), 2) if l else None,\n",
        "            \"lat_p95_ms\": round(pctl(l, 0.95), 2) if l else None,\n",
        "            \"lat_p99_ms\": round(pctl(l, 0.99), 2) if l else None,\n",
        "            \"lat_mean_ms\": round(statistics.mean(l), 2) if l else None,\n",
        "        }"
      ],
      "metadata": {
        "id": "tUvXpoomA6ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class FailureModel:\n",
        "    base_latency_ms: float = 8.0\n",
        "    jitter_ms: float = 6.0\n",
        "    fail_prob: float = 0.05\n",
        "    overload_fail_prob: float = 0.40\n",
        "    overload_latency_ms: float = 50.0\n",
        "\n",
        "    def sample(self, load_factor: float):\n",
        "        base = self.base_latency_ms + random.random() * self.jitter_ms\n",
        "        if load_factor > 1.0:\n",
        "            base += (load_factor - 1.0) * self.overload_latency_ms\n",
        "            fail_p = min(0.95, self.fail_prob + (load_factor - 1.0) * self.overload_fail_prob)\n",
        "        else:\n",
        "            fail_p = self.fail_prob\n",
        "        return base, (random.random() < fail_p)\n",
        "\n",
        "class CircuitBreaker:\n",
        "    def __init__(self, fail_threshold=8, window=20, open_ms=500):\n",
        "        self.fail_threshold = fail_threshold\n",
        "        self.window = window\n",
        "        self.open_ms = open_ms\n",
        "        self.events = deque(maxlen=window)\n",
        "        self.open_until_ms = 0.0\n",
        "\n",
        "    def allow(self):\n",
        "        return now_ms() >= self.open_until_ms\n",
        "\n",
        "    def record(self, ok: bool):\n",
        "        self.events.append(not ok)\n",
        "        if len(self.events) >= self.window and sum(self.events) >= self.fail_threshold:\n",
        "            self.open_until_ms = now_ms() + self.open_ms\n",
        "\n",
        "class Bulkhead:\n",
        "    def __init__(self, limit):\n",
        "        self.sem = asyncio.Semaphore(limit)\n",
        "\n",
        "    async def __aenter__(self):\n",
        "        await self.sem.acquire()\n",
        "\n",
        "    async def __aexit__(self, exc_type, exc, tb):\n",
        "        self.sem.release()\n",
        "\n",
        "def exp_backoff(attempt, base_ms=20, cap_ms=400):\n",
        "    return random.random() * min(cap_ms, base_ms * (2 ** (attempt - 1)))"
      ],
      "metadata": {
        "id": "ezQp-jguA6id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DownstreamService:\n",
        "    def __init__(self, fm: FailureModel, capacity_rps=250):\n",
        "        self.fm = fm\n",
        "        self.capacity_rps = capacity_rps\n",
        "        self._inflight = 0\n",
        "\n",
        "    async def handle(self, payload: dict):\n",
        "        self._inflight += 1\n",
        "        try:\n",
        "            load_factor = max(0.5, self._inflight / (self.capacity_rps / 10))\n",
        "            lat, should_fail = self.fm.sample(load_factor)\n",
        "            await asyncio.sleep(lat / 1000.0)\n",
        "            if should_fail:\n",
        "                raise RuntimeError(\"downstream_error\")\n",
        "            return {\"status\": \"ok\"}\n",
        "        finally:\n",
        "            self._inflight -= 1\n",
        "\n",
        "async def rpc_call(\n",
        "    svc,\n",
        "    req,\n",
        "    stats,\n",
        "    timeout_ms=120,\n",
        "    max_retries=0,\n",
        "    cb=None,\n",
        "    bulkhead=None,\n",
        "):\n",
        "    t0 = now_ms()\n",
        "    if cb and not cb.allow():\n",
        "        stats.cb_open += 1\n",
        "        stats.fail += 1\n",
        "        return False\n",
        "\n",
        "    attempt = 0\n",
        "    while True:\n",
        "        attempt += 1\n",
        "        try:\n",
        "            if bulkhead:\n",
        "                async with bulkhead:\n",
        "                    await asyncio.wait_for(svc.handle(req), timeout=timeout_ms / 1000.0)\n",
        "            else:\n",
        "                await asyncio.wait_for(svc.handle(req), timeout=timeout_ms / 1000.0)\n",
        "            stats.latencies_ms.append(now_ms() - t0)\n",
        "            stats.ok += 1\n",
        "            if cb: cb.record(True)\n",
        "            return True\n",
        "        except asyncio.TimeoutError:\n",
        "            stats.timeouts += 1\n",
        "        except Exception:\n",
        "            pass\n",
        "        stats.fail += 1\n",
        "        if cb: cb.record(False)\n",
        "        if attempt <= max_retries:\n",
        "            stats.retries += 1\n",
        "            await asyncio.sleep(exp_backoff(attempt) / 1000.0)\n",
        "            continue\n",
        "        return False"
      ],
      "metadata": {
        "id": "Fer3WAwBA6f1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Event:\n",
        "    id: int\n",
        "    tries: int = 0\n",
        "\n",
        "class EventBus:\n",
        "    def __init__(self, max_queue=5000):\n",
        "        self.q = asyncio.Queue(maxsize=max_queue)\n",
        "\n",
        "    async def publish(self, e: Event):\n",
        "        try:\n",
        "            self.q.put_nowait(e)\n",
        "            return True\n",
        "        except asyncio.QueueFull:\n",
        "            return False\n",
        "\n",
        "async def event_consumer(\n",
        "    bus,\n",
        "    svc,\n",
        "    stats,\n",
        "    stop,\n",
        "    max_retries=0,\n",
        "    dlq=None,\n",
        "    bulkhead=None,\n",
        "    timeout_ms=200,\n",
        "):\n",
        "    while not stop.is_set() or not bus.q.empty():\n",
        "        try:\n",
        "            e = await asyncio.wait_for(bus.q.get(), timeout=0.2)\n",
        "        except asyncio.TimeoutError:\n",
        "            continue\n",
        "\n",
        "        t0 = now_ms()\n",
        "        e.tries += 1\n",
        "        try:\n",
        "            if bulkhead:\n",
        "                async with bulkhead:\n",
        "                    await asyncio.wait_for(svc.handle({\"id\": e.id}), timeout=timeout_ms / 1000.0)\n",
        "            else:\n",
        "                await asyncio.wait_for(svc.handle({\"id\": e.id}), timeout=timeout_ms / 1000.0)\n",
        "            stats.ok += 1\n",
        "            stats.latencies_ms.append(now_ms() - t0)\n",
        "        except Exception:\n",
        "            stats.fail += 1\n",
        "            if e.tries <= max_retries:\n",
        "                stats.retries += 1\n",
        "                await asyncio.sleep(exp_backoff(e.tries) / 1000.0)\n",
        "                await bus.publish(e)\n",
        "            else:\n",
        "                stats.dlq += 1\n",
        "                if dlq is not None:\n",
        "                    dlq.append(e)\n",
        "        finally:\n",
        "            bus.q.task_done()"
      ],
      "metadata": {
        "id": "znWhO1MmA6dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3LFzzhIgi0t",
        "outputId": "26cdb1f1-2db7-49de-86e4-ce9d6de56335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.12/asyncio/events.py:111: RuntimeWarning: coroutine 'experiment' was never awaited\n",
            "  def __init__(self, when, callback, args, loop, context=None):\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Metrics Summary ===\n",
            "name                                           | ok   | fail | dropped | retries | timeouts | cb_open | dlq | lat_p50_ms | lat_p95_ms | lat_p99_ms | throughput_rps | total_ms\n",
            "-----------------------------------------------+------+------+---------+---------+----------+---------+-----+------------+------------+------------+----------------+---------\n",
            "RPC naive (retries=3, no CB)                   | 57   | 9396 | 0       | 7053    | 9354     | 0       | 0   | 17.81      | 528.84     | 581.83     | 470.7          | 5098.5  \n",
            "RPC safe (retries=1, CB+bulkhead)              | 201  | 2394 | 0       | 195     | 0        | 2074    | 0   | 352.01     | 787.99     | 807.33     | 2821.3         | 850.7   \n",
            "Event naive (retries=3, small queue)           | 1400 | 44   | 1000    | 44      | 0        | 0       | 0   | 12.68      | 16.18      | 16.67      | 1086.8         | 1288.1  \n",
            "Event safe (retries=1, bulkhead, larger queue) | 2400 | 72   | 0       | 72      | 0        | 0       | 0   | 22.55      | 27.08      | 28.59      | 716.5          | 3349.6  \n",
            "\n",
            "=== DLQ Samples (first 8 ids) ===\n",
            "DLQ naive: []\n",
            "DLQ safe : []\n",
            "\n",
            "=== Interpretation Guide ===\n",
            "- RPC tends to show lower p50 latency when healthy, but can amplify failures with synchronous retries.\n",
            "- Event-driven decouples producers/consumers (good for coupling + resilience), but queues can hide overload and grow tail latency.\n",
            "- Retry storms show up as rising 'retries' + worse p95/p99 + more failures/timeouts.\n",
            "- Circuit breakers and bulkheads reduce cascading failures (see cb_open + improved tail lat / failures).\n",
            "- DLQ is a safety valve: bounded retries => failures become observable + recoverable instead of infinite requeue.\n"
          ]
        }
      ],
      "source": [
        "async def generate_requests(total=2000, burst=350, gap_ms=80):\n",
        "    reqs = []\n",
        "    rid = 0\n",
        "    while rid < total:\n",
        "        n = min(burst, total - rid)\n",
        "        for _ in range(n):\n",
        "            reqs.append(rid)\n",
        "            rid += 1\n",
        "        await asyncio.sleep(gap_ms / 1000.0)\n",
        "    return reqs\n",
        "\n",
        "async def main():\n",
        "    random.seed(7)\n",
        "    fm = FailureModel()\n",
        "    svc = DownstreamService(fm)\n",
        "    ids = await generate_requests()\n",
        "\n",
        "    rpc_stats = Stats()\n",
        "    cb = CircuitBreaker()\n",
        "    bulk = Bulkhead(40)\n",
        "\n",
        "    await asyncio.gather(*[\n",
        "        rpc_call(svc, {\"id\": i}, rpc_stats, max_retries=3, cb=cb, bulkhead=bulk)\n",
        "        for i in ids\n",
        "    ])\n",
        "\n",
        "    bus = EventBus()\n",
        "    ev_stats = Stats()\n",
        "    stop = asyncio.Event()\n",
        "    dlq = []\n",
        "\n",
        "    consumers = [\n",
        "        asyncio.create_task(event_consumer(bus, svc, ev_stats, stop, max_retries=3, dlq=dlq))\n",
        "        for _ in range(16)\n",
        "    ]\n",
        "\n",
        "    for i in ids:\n",
        "        await bus.publish(Event(i))\n",
        "\n",
        "    await bus.q.join()\n",
        "    stop.set()\n",
        "    for c in consumers:\n",
        "        c.cancel()\n",
        "\n",
        "    print(rpc_stats.summary(\"RPC\"))\n",
        "    print(ev_stats.summary(\"EventDriven\"))\n",
        "    print(\"DLQ size:\", len(dlq))\n",
        "\n",
        "await main()"
      ]
    }
  ]
}