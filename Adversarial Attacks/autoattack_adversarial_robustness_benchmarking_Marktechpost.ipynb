{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U robustbench\n",
        "!pip -q install -U git+https://github.com/fra31/auto-attack\n",
        "\n",
        "import os, time, math, random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from robustbench.utils import load_model\n",
        "from autoattack import AutoAttack\n",
        "\n",
        "def seed_all(seed=0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_all(0)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "if device == \"cpu\":\n",
        "    print(\"⚠️ Tip: Colab → Runtime → Change runtime type → GPU (AutoAttack is much slower on CPU)\")"
      ],
      "metadata": {
        "id": "GqAMB1VH5I43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cifar_mean = (0.4914, 0.4822, 0.4465)\n",
        "cifar_std  = (0.2470, 0.2435, 0.2616)\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(cifar_mean, cifar_std),\n",
        "])\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "N_EXAMPLES = 1000\n",
        "BATCH_SIZE = 128 if device == \"cuda\" else 64\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "idx = np.random.RandomState(0).choice(len(testset), size=N_EXAMPLES, replace=False)\n",
        "test_subset = Subset(testset, idx.tolist())\n",
        "test_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=(device==\"cuda\"))\n",
        "\n",
        "@torch.no_grad()\n",
        "def loader_to_tensors(loader, device):\n",
        "    xs, ys = [], []\n",
        "    for x, y in loader:\n",
        "        xs.append(x)\n",
        "        ys.append(y)\n",
        "    x = torch.cat(xs, dim=0).to(device)\n",
        "    y = torch.cat(ys, dim=0).to(device)\n",
        "    return x, y\n",
        "\n",
        "x_test, y_test = loader_to_tensors(test_loader, device)\n",
        "print(\"x_test:\", tuple(x_test.shape), \"y_test:\", tuple(y_test.shape))"
      ],
      "metadata": {
        "id": "Rsnw81XD5Ivc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_SPECS = [\n",
        "    (\"Standard\", \"cifar10\", \"Linf\"),\n",
        "    (\"Wong2020Fast\", \"cifar10\", \"Linf\"),\n",
        "    (\"Rebuffi2021Fixing_70_16_cutmix_extra\", \"cifar10\", \"Linf\"),\n",
        "]\n",
        "\n",
        "def try_load_rb_model(name, dataset, threat_model, device):\n",
        "    try:\n",
        "        m = load_model(model_name=name, dataset=dataset, threat_model=threat_model).to(device)\n",
        "        m.eval()\n",
        "        return m\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to load {name} ({dataset}, {threat_model}). Reason:\\n   {type(e).__name__}: {e}\\n   -> Skipping.\")\n",
        "        return None\n",
        "\n",
        "models = []\n",
        "for name, ds, tm in MODEL_SPECS:\n",
        "    m = try_load_rb_model(name, ds, tm, device)\n",
        "    if m is not None:\n",
        "        models.append((name, m))\n",
        "\n",
        "print(\"\\nLoaded models:\", [n for n,_ in models])\n",
        "assert len(models) > 0, \"No models loaded; check install/runtime.\"\n",
        "\n",
        "@torch.no_grad()\n",
        "def accuracy(model, x, y, batch_size=256):\n",
        "    n = x.shape[0]\n",
        "    correct = 0\n",
        "    for i in range(0, n, batch_size):\n",
        "        xb = x[i:i+batch_size]\n",
        "        yb = y[i:i+batch_size]\n",
        "        logits = model(xb)\n",
        "        pred = logits.argmax(dim=1)\n",
        "        correct += (pred == yb).sum().item()\n",
        "    return correct / n"
      ],
      "metadata": {
        "id": "F7U0jLGp5Isc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPS_LIST = [0/255, 1/255, 2/255, 4/255, 8/255]\n",
        "\n",
        "AA_VERSION = \"standard\"\n",
        "\n",
        "ATTACKS_TO_RUN = None\n",
        "\n",
        "def run_autoattack(model, x, y, eps, version=\"standard\", attacks_to_run=None, seed=0):\n",
        "    adversary = AutoAttack(model, norm=\"Linf\", eps=eps, version=version, device=device)\n",
        "    if attacks_to_run is not None:\n",
        "        adversary.attacks_to_run = attacks_to_run\n",
        "    adversary.seed = seed\n",
        "    x_adv = adversary.run_standard_evaluation(x, y, bs=BATCH_SIZE)\n",
        "    return x_adv\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"Model:\", name)\n",
        "\n",
        "    clean_acc = accuracy(model, x_test, y_test, batch_size=BATCH_SIZE)\n",
        "    print(f\"Clean accuracy on subset: {clean_acc*100:.2f}%\")\n",
        "\n",
        "    curve = []\n",
        "    for eps in EPS_LIST:\n",
        "        if eps == 0:\n",
        "            curve.append((eps, clean_acc, clean_acc))\n",
        "            continue\n",
        "\n",
        "        t0 = time.time()\n",
        "        x_adv = run_autoattack(model, x_test, y_test, eps=eps, version=AA_VERSION, attacks_to_run=ATTACKS_TO_RUN, seed=0)\n",
        "        rob_acc = accuracy(model, x_adv, y_test, batch_size=BATCH_SIZE)\n",
        "        dt = time.time() - t0\n",
        "\n",
        "        print(f\"  eps={eps:.5f} ({eps*255:.1f}/255)  robust_acc={rob_acc*100:.2f}%   time={dt/60:.1f} min\")\n",
        "        curve.append((eps, clean_acc, rob_acc))\n",
        "\n",
        "        del x_adv\n",
        "        if device == \"cuda\":\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    results[name] = curve"
      ],
      "metadata": {
        "id": "HK3QXnR_5Ipj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2fAfLI6pol6",
        "outputId": "46584d5e-ab62-47c1-aa1a-6db31653f33f"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.9/90.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m967.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for autoattack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Device: cpu\n",
            "⚠️ Tip: Colab → Runtime → Change runtime type → GPU (AutoAttack is much slower on CPU)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:02<00:00, 77.9MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_test: (1000, 3, 32, 32) y_test: (1000,)\n",
            "Downloading models/cifar10/Linf/Standard.pt (gdrive_id=1t98aEuzeTL8P7Kpd5DIrCoCL21BNZUhC).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1t98aEuzeTL8P7Kpd5DIrCoCL21BNZUhC\n",
            "From (redirected): https://drive.google.com/uc?id=1t98aEuzeTL8P7Kpd5DIrCoCL21BNZUhC&confirm=t&uuid=5f38f5ca-1ccf-4a1c-bcb1-58d241b029f5\n",
            "To: /content/models/cifar10/Linf/Standard.pt\n",
            "100%|██████████| 292M/292M [00:02<00:00, 139MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading models/cifar10/Linf/Wong2020Fast.pt (gdrive_id=1Re--_lf3jCEw9bnQqGkjw3J7v2tSZKrv).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Re--_lf3jCEw9bnQqGkjw3J7v2tSZKrv\n",
            "To: /content/models/cifar10/Linf/Wong2020Fast.pt\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 108MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading models/cifar10/Linf/Rebuffi2021Fixing_70_16_cutmix_extra.pt (gdrive_id=1qKDTp6IJ1BUXZaRtbYuo_t0tuDl_4mLg).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1qKDTp6IJ1BUXZaRtbYuo_t0tuDl_4mLg\n",
            "From (redirected): https://drive.google.com/uc?id=1qKDTp6IJ1BUXZaRtbYuo_t0tuDl_4mLg&confirm=t&uuid=ac5aca05-95d9-46d1-a500-997e620f1ec4\n",
            "To: /content/models/cifar10/Linf/Rebuffi2021Fixing_70_16_cutmix_extra.pt\n",
            "100%|██████████| 1.07G/1.07G [00:04<00:00, 238MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded models: ['Standard', 'Wong2020Fast', 'Rebuffi2021Fixing_70_16_cutmix_extra']\n",
            "\n",
            "================================================================================\n",
            "Model: Standard\n",
            "Clean accuracy on subset: 30.40%\n",
            "setting parameters for standard version\n",
            "using standard version including apgd-ce, apgd-t, fab-t, square.\n",
            "initial accuracy: 30.40%\n",
            "apgd-ce - 1/5 - 22 out of 64 successfully perturbed\n",
            "apgd-ce - 2/5 - 24 out of 64 successfully perturbed\n",
            "apgd-ce - 3/5 - 27 out of 64 successfully perturbed\n",
            "apgd-ce - 4/5 - 32 out of 64 successfully perturbed\n",
            "apgd-ce - 5/5 - 24 out of 48 successfully perturbed\n",
            "robust accuracy after APGD-CE: 17.50% (total time 12038.3 s)\n"
          ]
        }
      ],
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "for name, curve in results.items():\n",
        "    eps_vals = [e*255 for (e, _, _) in curve]\n",
        "    rob_vals = [r*100 for (_, _, r) in curve]\n",
        "    plt.plot(eps_vals, rob_vals, marker=\"o\", label=name)\n",
        "\n",
        "plt.xlabel(\"L∞ perturbation budget ε (in /255)\")\n",
        "plt.ylabel(\"Accuracy under AutoAttack (%)\")\n",
        "plt.title(f\"AutoAttack Robustness Curves (CIFAR-10 subset n={N_EXAMPLES}, AA={AA_VERSION})\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nSummary (robust acc at 8/255):\")\n",
        "for name, curve in results.items():\n",
        "    r8 = None\n",
        "    for eps, _, rob in curve:\n",
        "        if abs(eps - (8/255)) < 1e-12:\n",
        "            r8 = rob\n",
        "            break\n",
        "    if r8 is not None:\n",
        "        print(f\"  {name:40s}  {r8*100:6.2f}%\")\n",
        "    else:\n",
        "        print(f\"  {name:40s}  (no 8/255 point)\")"
      ]
    }
  ]
}