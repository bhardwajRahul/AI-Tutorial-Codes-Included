{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U \"autogluon==1.5.0\" \"scikit-learn>=1.3\" \"pandas>=2.0\" \"numpy>=1.24\"\n",
        "\n",
        "import os, time, json, warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, log_loss, accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "from autogluon.tabular import TabularPredictor"
      ],
      "metadata": {
        "id": "P2bFovl7FMel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "df = fetch_openml(data_id=40945, as_frame=True).frame\n",
        "\n",
        "target = \"survived\"\n",
        "df[target] = df[target].astype(int)\n",
        "\n",
        "drop_cols = [c for c in [\"boat\", \"body\", \"home.dest\"] if c in df.columns]\n",
        "df = df.drop(columns=drop_cols, errors=\"ignore\")\n",
        "\n",
        "df = df.replace({None: np.nan})\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Target positive rate:\", df[target].mean().round(4))\n",
        "print(\"Columns:\", list(df.columns))\n",
        "\n",
        "train_df, test_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df[target],\n",
        ")"
      ],
      "metadata": {
        "id": "RIffzT32FMTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def has_gpu():\n",
        "    try:\n",
        "        import torch\n",
        "        return torch.cuda.is_available()\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "presets = \"extreme\" if has_gpu() else \"best_quality\"\n",
        "\n",
        "save_path = \"/content/autogluon_titanic_advanced\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "predictor = TabularPredictor(\n",
        "    label=target,\n",
        "    eval_metric=\"roc_auc\",\n",
        "    path=save_path,\n",
        "    verbosity=2\n",
        ")"
      ],
      "metadata": {
        "id": "IY1jKF-kFMHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "predictor.fit(\n",
        "    train_data=train_df,\n",
        "    presets=presets,\n",
        "    time_limit=7 * 60,\n",
        "    num_bag_folds=5,\n",
        "    num_stack_levels=2,\n",
        "    refit_full=False\n",
        ")\n",
        "train_time = time.time() - start\n",
        "print(f\"\\nTraining done in {train_time:.1f}s with presets='{presets}'\")"
      ],
      "metadata": {
        "id": "sGTaUJR8FMBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lb = predictor.leaderboard(test_df, silent=True)\n",
        "print(\"\\n=== Leaderboard (top 15) ===\")\n",
        "display(lb.head(15))\n",
        "\n",
        "proba = predictor.predict_proba(test_df)\n",
        "pred = predictor.predict(test_df)\n",
        "\n",
        "y_true = test_df[target].values\n",
        "if isinstance(proba, pd.DataFrame) and 1 in proba.columns:\n",
        "    y_proba = proba[1].values\n",
        "else:\n",
        "    y_proba = np.asarray(proba).reshape(-1)\n",
        "\n",
        "print(\"\\n=== Test Metrics ===\")\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_true, y_proba).round(5))\n",
        "print(\"LogLoss:\", log_loss(y_true, np.clip(y_proba, 1e-6, 1 - 1e-6)).round(5))\n",
        "print(\"Accuracy:\", accuracy_score(y_true, pred).round(5))\n",
        "print(\"\\nClassification report:\\n\", classification_report(y_true, pred))"
      ],
      "metadata": {
        "id": "5mlw739yFL_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if \"pclass\" in test_df.columns:\n",
        "    print(\"\\n=== Slice AUC by pclass ===\")\n",
        "    for grp, part in test_df.groupby(\"pclass\"):\n",
        "        part_proba = predictor.predict_proba(part)\n",
        "        part_proba = part_proba[1].values if isinstance(part_proba, pd.DataFrame) and 1 in part_proba.columns else np.asarray(part_proba).reshape(-1)\n",
        "        auc = roc_auc_score(part[target].values, part_proba)\n",
        "        print(f\"pclass={grp}: AUC={auc:.4f} (n={len(part)})\")\n",
        "\n",
        "fi = predictor.feature_importance(test_df, silent=True)\n",
        "print(\"\\n=== Feature importance (top 20) ===\")\n",
        "display(fi.head(20))"
      ],
      "metadata": {
        "id": "Zq-Z84OkFL8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytO0R4eVBQim",
        "outputId": "d22926d7-cb2b-4d41-9ae8-358fc24ae118"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/content/autogluon_titanic_advanced\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.5.0\n",
            "Python Version:     3.12.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
            "CPU Count:          2\n",
            "Pytorch Version:    2.9.0+cpu\n",
            "CUDA Version:       CUDA is not available\n",
            "Memory Avail:       10.04 GB / 12.67 GB (79.2%)\n",
            "Disk Space Avail:   85.40 GB / 107.72 GB (79.3%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "Using hyperparameters preset: hyperparameters='zeroshot'\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=2, num_bag_folds=5, num_bag_sets=1\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 105s of the 420s of remaining time (25%).\n",
            "\t\tContext path: \"/content/autogluon_titanic_advanced/ds_sub_fit/sub_fit_ho\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (1309, 11)\n",
            "Target positive rate: 0.382\n",
            "Columns: ['pclass', 'survived', 'name', 'sex', 'age', 'sibsp', 'parch', 'ticket', 'fare', 'cabin', 'embarked']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Leaderboard on holdout data (DyStack):\n",
            "                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0      LightGBM_BAG_L2       0.866975   0.837793     roc_auc        1.220580       0.465710  42.812524                 0.035893                0.057318          17.013317            2       True          4\n",
            "1    LightGBMXT_BAG_L2       0.863580   0.844238     roc_auc        1.228134       0.447580  44.289877                 0.043447                0.039188          18.490669            2       True          3\n",
            "2  WeightedEnsemble_L4       0.863580   0.844238     roc_auc        1.230090       0.448575  44.294562                 0.001956                0.000994           0.004685            4       True          7\n",
            "3  WeightedEnsemble_L3       0.863580   0.844238     roc_auc        1.230333       0.448662  44.295093                 0.002198                0.001081           0.005216            3       True          5\n",
            "4    LightGBMXT_BAG_L1       0.861728   0.843358     roc_auc        1.184687       0.408392  25.799207                 1.184687                0.408392          25.799207            1       True          1\n",
            "5  WeightedEnsemble_L2       0.861728   0.843358     roc_auc        1.186750       0.409494  25.804795                 0.002063                0.001102           0.005587            2       True          2\n",
            "6    LightGBMXT_BAG_L3       0.856173   0.837764     roc_auc        1.274912       0.538619  62.797620                 0.046778                0.091039          18.507744            3       True          6\n",
            "\t2\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
            "\t137s\t = DyStack   runtime |\t283s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=2.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=2)`\n",
            "Beginning AutoGluon training ... Time limit = 283s\n",
            "AutoGluon will save models to \"/content/autogluon_titanic_advanced\"\n",
            "Train Data Rows:    1047\n",
            "Train Data Columns: 10\n",
            "Label Column:       survived\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    9844.63 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.21 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['name']\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 12\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('category', [])     : 2 | ['sex', 'embarked']\n",
            "\t\t('float', [])        : 2 | ['age', 'fare']\n",
            "\t\t('int', [])          : 3 | ['pclass', 'sibsp', 'parch']\n",
            "\t\t('object', [])       : 2 | ['ticket', 'cabin']\n",
            "\t\t('object', ['text']) : 1 | ['name']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    :  3 | ['ticket', 'cabin', 'embarked']\n",
            "\t\t('float', [])                       :  2 | ['age', 'fare']\n",
            "\t\t('int', [])                         :  3 | ['pclass', 'sibsp', 'parch']\n",
            "\t\t('int', ['binned', 'text_special']) :  8 | ['name.char_count', 'name.word_count', 'name.capital_ratio', 'name.lower_ratio', 'name.special_ratio', ...]\n",
            "\t\t('int', ['bool'])                   :  1 | ['sex']\n",
            "\t\t('int', ['text_ngram'])             : 13 | ['__nlp__.charles', '__nlp__.george', '__nlp__.henry', '__nlp__.james', '__nlp__.john', ...]\n",
            "\t0.4s = Fit runtime\n",
            "\t10 features in original data used to generate 30 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.08 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.45s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "}\n",
            "AutoGluon will fit 3 stack levels (L1 to L3) ...\n",
            "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 125.41s of the 282.21s of remaining time.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.21%)\n",
            "\t0.8479\t = Validation score   (roc_auc)\n",
            "\t17.27s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 102.94s of the 259.74s of remaining time.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.21%)\n",
            "\t0.8497\t = Validation score   (roc_auc)\n",
            "\t17.26s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 78.53s of the 235.34s of remaining time.\n",
            "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=2, gpus=0\n",
            "\t0.836\t = Validation score   (roc_auc)\n",
            "\t1.42s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 76.90s of the 233.70s of remaining time.\n",
            "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=2, gpus=0\n",
            "\t0.8353\t = Validation score   (roc_auc)\n",
            "\t1.13s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 75.54s of the 232.35s of remaining time.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=4.08%)\n",
            "\t0.8779\t = Validation score   (roc_auc)\n",
            "\t22.82s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 45.57s of the 202.37s of remaining time.\n",
            "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=2, gpus=0\n",
            "\t0.8291\t = Validation score   (roc_auc)\n",
            "\t1.23s\t = Training   runtime\n",
            "\t0.18s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 44.07s of the 200.87s of remaining time.\n",
            "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=2, gpus=0\n",
            "\t0.8303\t = Validation score   (roc_auc)\n",
            "\t1.62s\t = Training   runtime\n",
            "\t0.25s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 42.11s of the 198.91s of remaining time.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
            "\t0.8759\t = Validation score   (roc_auc)\n",
            "\t34.1s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ... Training model for up to 2.45s of the 159.25s of remaining time.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
            "\t0.8518\t = Validation score   (roc_auc)\n",
            "\t10.11s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 282.24s of the 141.46s of remaining time.\n",
            "\tFitting 1 model on all data | Fitting with cpus=2, gpus=0, mem=0.0/9.8 GB\n",
            "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.545, 'CatBoost_BAG_L1': 0.364, 'LightGBM_BAG_L1': 0.091}\n",
            "\t0.8883\t = Validation score   (roc_auc)\n",
            "\t0.23s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 94.12s of the 141.15s of remaining time.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
            "\t0.8877\t = Validation score   (roc_auc)\n",
            "\t16.61s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 70.85s of the 117.89s of remaining time.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
            "\t0.8925\t = Validation score   (roc_auc)\n",
            "\t17.82s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 48.01s of the 95.05s of remaining time.\n",
            "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=2, gpus=0\n",
            "\t0.8867\t = Validation score   (roc_auc)\n",
            "\t2.34s\t = Training   runtime\n",
            "\t0.32s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 45.27s of the 92.31s of remaining time.\n",
            "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=2, gpus=0\n",
            "\t0.8929\t = Validation score   (roc_auc)\n",
            "\t1.62s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L2 ... Training model for up to 43.45s of the 90.48s of remaining time.\n",
            "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=4.10%)\n"
          ]
        }
      ],
      "source": [
        "t0 = time.time()\n",
        "refit_map = predictor.refit_full()\n",
        "t_refit = time.time() - t0\n",
        "\n",
        "print(f\"\\nrefit_full completed in {t_refit:.1f}s\")\n",
        "print(\"Refit mapping (sample):\", dict(list(refit_map.items())[:5]))\n",
        "\n",
        "lb_full = predictor.leaderboard(test_df, silent=True)\n",
        "print(\"\\n=== Leaderboard after refit_full (top 15) ===\")\n",
        "display(lb_full.head(15))\n",
        "\n",
        "best_model = predictor.get_model_best()\n",
        "full_candidates = [m for m in predictor.get_model_names() if m.endswith(\"_FULL\")]\n",
        "\n",
        "def bench_infer(model_name, df_in, repeats=3):\n",
        "    times = []\n",
        "    for _ in range(repeats):\n",
        "        t1 = time.time()\n",
        "        _ = predictor.predict(df_in, model=model_name)\n",
        "        times.append(time.time() - t1)\n",
        "    return float(np.median(times))\n",
        "\n",
        "small_batch = test_df.drop(columns=[target]).head(256)\n",
        "lat_best = bench_infer(best_model, small_batch)\n",
        "print(f\"\\nBest model: {best_model} | median predict() latency on 256 rows: {lat_best:.4f}s\")\n",
        "\n",
        "if full_candidates:\n",
        "    lb_full_sorted = lb_full.sort_values(by=\"score_test\", ascending=False)\n",
        "    best_full = lb_full_sorted[lb_full_sorted[\"model\"].str.endswith(\"_FULL\")].iloc[0][\"model\"]\n",
        "    lat_full = bench_infer(best_full, small_batch)\n",
        "    print(f\"Best FULL model: {best_full} | median predict() latency on 256 rows: {lat_full:.4f}s\")\n",
        "    print(f\"Speedup factor (best / full): {lat_best / max(lat_full, 1e-9):.2f}x\")\n",
        "\n",
        "try:\n",
        "    t0 = time.time()\n",
        "    distill_result = predictor.distill(\n",
        "        train_data=train_df,\n",
        "        time_limit=4 * 60,\n",
        "        augment_method=\"spunge\",\n",
        "    )\n",
        "    t_distill = time.time() - t0\n",
        "    print(f\"\\nDistillation completed in {t_distill:.1f}s\")\n",
        "except Exception as e:\n",
        "    print(\"\\nDistillation step failed\")\n",
        "    print(\"Error:\", repr(e))\n",
        "\n",
        "lb2 = predictor.leaderboard(test_df, silent=True)\n",
        "print(\"\\n=== Leaderboard after distillation attempt (top 20) ===\")\n",
        "display(lb2.head(20))\n",
        "\n",
        "predictor.save()\n",
        "reloaded = TabularPredictor.load(save_path)\n",
        "\n",
        "sample = test_df.drop(columns=[target]).sample(8, random_state=0)\n",
        "sample_pred = reloaded.predict(sample)\n",
        "sample_proba = reloaded.predict_proba(sample)\n",
        "\n",
        "print(\"\\n=== Reloaded predictor sanity-check ===\")\n",
        "print(sample.assign(pred=sample_pred).head())\n",
        "\n",
        "print(\"\\nProbabilities (head):\")\n",
        "display(sample_proba.head())\n",
        "\n",
        "artifacts = {\n",
        "    \"path\": save_path,\n",
        "    \"presets\": presets,\n",
        "    \"best_model\": reloaded.get_model_best(),\n",
        "    \"model_names\": reloaded.get_model_names(),\n",
        "    \"leaderboard_top10\": lb2.head(10).to_dict(orient=\"records\"),\n",
        "}\n",
        "with open(os.path.join(save_path, \"run_summary.json\"), \"w\") as f:\n",
        "    json.dump(artifacts, f, indent=2)\n",
        "\n",
        "print(\"\\nSaved summary to:\", os.path.join(save_path, \"run_summary.json\"))\n",
        "print(\"Done.\")"
      ]
    }
  ]
}