{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ivy tensorflow torch jax jaxlib\n",
        "\n",
        "import ivy\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "print(f\"Ivy version: {ivy.__version__}\")\n",
        "\n",
        "\n",
        "class IvyNeuralNetwork:\n",
        "    \"\"\"A simple neural network written purely in Ivy that works with any backend.\"\"\"\n",
        "\n",
        "    def __init__(self, input_dim=4, hidden_dim=8, output_dim=3):\n",
        "        self.w1 = ivy.random_uniform(shape=(input_dim, hidden_dim), low=-0.5, high=0.5)\n",
        "        self.b1 = ivy.zeros((hidden_dim,))\n",
        "        self.w2 = ivy.random_uniform(shape=(hidden_dim, output_dim), low=-0.5, high=0.5)\n",
        "        self.b2 = ivy.zeros((output_dim,))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass using pure Ivy operations.\"\"\"\n",
        "        h = ivy.matmul(x, self.w1) + self.b1\n",
        "        h = ivy.relu(h)\n",
        "\n",
        "        out = ivy.matmul(h, self.w2) + self.b2\n",
        "        return ivy.softmax(out)\n",
        "\n",
        "    def train_step(self, x, y, lr=0.01):\n",
        "        \"\"\"Simple training step with manual gradients.\"\"\"\n",
        "        pred = self.forward(x)\n",
        "\n",
        "        loss = -ivy.mean(ivy.sum(y * ivy.log(pred + 1e-8), axis=-1))\n",
        "\n",
        "        pred_error = pred - y\n",
        "\n",
        "        h_activated = ivy.relu(ivy.matmul(x, self.w1) + self.b1)\n",
        "        h_t = ivy.permute_dims(h_activated, axes=(1, 0))\n",
        "        dw2 = ivy.matmul(h_t, pred_error) / x.shape[0]\n",
        "        db2 = ivy.mean(pred_error, axis=0)\n",
        "\n",
        "        self.w2 = self.w2 - lr * dw2\n",
        "        self.b2 = self.b2 - lr * db2\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "def demo_framework_agnostic_network():\n",
        "    \"\"\"Demonstrate the same network running on different backends.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"PART 1: Framework-Agnostic Neural Network\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    X = np.random.randn(100, 4).astype(np.float32)\n",
        "    y = np.eye(3)[np.random.randint(0, 3, 100)].astype(np.float32)\n",
        "\n",
        "    backends = ['numpy', 'torch', 'tensorflow', 'jax']\n",
        "    results = {}\n",
        "\n",
        "    for backend in backends:\n",
        "        try:\n",
        "            ivy.set_backend(backend)\n",
        "\n",
        "            if backend == 'jax':\n",
        "                import jax\n",
        "                jax.config.update('jax_enable_x64', True)\n",
        "\n",
        "            print(f\"\\nğŸ”„ Running with {backend.upper()} backend...\")\n",
        "\n",
        "            X_ivy = ivy.array(X)\n",
        "            y_ivy = ivy.array(y)\n",
        "\n",
        "            net = IvyNeuralNetwork()\n",
        "\n",
        "            start_time = time.time()\n",
        "            for epoch in range(50):\n",
        "                loss = net.train_step(X_ivy, y_ivy, lr=0.1)\n",
        "\n",
        "            elapsed = time.time() - start_time\n",
        "\n",
        "            predictions = net.forward(X_ivy)\n",
        "            accuracy = ivy.mean(\n",
        "                ivy.astype(ivy.argmax(predictions, axis=-1) == ivy.argmax(y_ivy, axis=-1), 'float32')\n",
        "            )\n",
        "\n",
        "            results[backend] = {\n",
        "                'loss': float(ivy.to_numpy(loss)),\n",
        "                'accuracy': float(ivy.to_numpy(accuracy)),\n",
        "                'time': elapsed\n",
        "            }\n",
        "\n",
        "            print(f\"   Final Loss: {results[backend]['loss']:.4f}\")\n",
        "            print(f\"   Accuracy: {results[backend]['accuracy']:.2%}\")\n",
        "            print(f\"   Time: {results[backend]['time']:.3f}s\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   âš ï¸ {backend} error: {str(e)[:80]}\")\n",
        "            results[backend] = None\n",
        "\n",
        "    ivy.unset_backend()\n",
        "    return results"
      ],
      "metadata": {
        "id": "sSrU9f-oYY0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def demo_transpilation():\n",
        "    \"\"\"Demonstrate transpiling code from PyTorch to TensorFlow and JAX.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"PART 2: Framework Transpilation\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    try:\n",
        "        import torch\n",
        "        import tensorflow as tf\n",
        "\n",
        "        def pytorch_computation(x):\n",
        "            \"\"\"A simple PyTorch computation.\"\"\"\n",
        "            return torch.mean(torch.relu(x * 2.0 + 1.0))\n",
        "\n",
        "        x_torch = torch.randn(10, 5)\n",
        "\n",
        "        print(\"\\nğŸ“¦ Original PyTorch function:\")\n",
        "        result_torch = pytorch_computation(x_torch)\n",
        "        print(f\"   PyTorch result: {result_torch.item():.6f}\")\n",
        "\n",
        "        print(\"\\nğŸ”„ Transpilation Demo:\")\n",
        "        print(\"   Note: ivy.transpile() is powerful but complex.\")\n",
        "        print(\"   It works best with traced/compiled functions.\")\n",
        "        print(\"   For simple demonstrations, we'll show the unified API instead.\")\n",
        "\n",
        "        print(\"\\nâœ¨ Equivalent computation across frameworks:\")\n",
        "        x_np = x_torch.numpy()\n",
        "\n",
        "        ivy.set_backend('numpy')\n",
        "        x_ivy = ivy.array(x_np)\n",
        "        result_np = ivy.mean(ivy.relu(x_ivy * 2.0 + 1.0))\n",
        "        print(f\"   NumPy result: {float(ivy.to_numpy(result_np)):.6f}\")\n",
        "\n",
        "        ivy.set_backend('tensorflow')\n",
        "        x_ivy = ivy.array(x_np)\n",
        "        result_tf = ivy.mean(ivy.relu(x_ivy * 2.0 + 1.0))\n",
        "        print(f\"   TensorFlow result: {float(ivy.to_numpy(result_tf)):.6f}\")\n",
        "\n",
        "        ivy.set_backend('jax')\n",
        "        import jax\n",
        "        jax.config.update('jax_enable_x64', True)\n",
        "        x_ivy = ivy.array(x_np)\n",
        "        result_jax = ivy.mean(ivy.relu(x_ivy * 2.0 + 1.0))\n",
        "        print(f\"   JAX result: {float(ivy.to_numpy(result_jax)):.6f}\")\n",
        "\n",
        "        print(f\"\\n   âœ… All results match within numerical precision!\")\n",
        "\n",
        "        ivy.unset_backend()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Demo error: {str(e)[:80]}\")"
      ],
      "metadata": {
        "id": "yyMiUwDzYmYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def demo_unified_api():\n",
        "    \"\"\"Show how Ivy's unified API works across different operations.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"PART 3: Unified API Across Frameworks\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    operations = [\n",
        "        (\"Matrix Multiplication\", lambda x: ivy.matmul(x, ivy.permute_dims(x, axes=(1, 0)))),\n",
        "        (\"Element-wise Operations\", lambda x: ivy.add(ivy.multiply(x, x), 2)),\n",
        "        (\"Reductions\", lambda x: ivy.mean(ivy.sum(x, axis=0))),\n",
        "        (\"Neural Net Ops\", lambda x: ivy.mean(ivy.relu(x))),\n",
        "        (\"Statistical Ops\", lambda x: ivy.std(x)),\n",
        "        (\"Broadcasting\", lambda x: ivy.multiply(x, ivy.array([1.0, 2.0, 3.0, 4.0]))),\n",
        "    ]\n",
        "\n",
        "    X = np.random.randn(5, 4).astype(np.float32)\n",
        "\n",
        "    for op_name, op_func in operations:\n",
        "        print(f\"\\nğŸ”§ {op_name}:\")\n",
        "\n",
        "        for backend in ['numpy', 'torch', 'tensorflow', 'jax']:\n",
        "            try:\n",
        "                ivy.set_backend(backend)\n",
        "\n",
        "                if backend == 'jax':\n",
        "                    import jax\n",
        "                    jax.config.update('jax_enable_x64', True)\n",
        "\n",
        "                x_ivy = ivy.array(X)\n",
        "                result = op_func(x_ivy)\n",
        "                result_np = ivy.to_numpy(result)\n",
        "\n",
        "                if result_np.shape == ():\n",
        "                    print(f\"   {backend:12s}: scalar value = {float(result_np):.4f}\")\n",
        "                else:\n",
        "                    print(f\"   {backend:12s}: shape={result_np.shape}, mean={np.mean(result_np):.4f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"   {backend:12s}: âš ï¸ {str(e)[:60]}\")\n",
        "\n",
        "        ivy.unset_backend()"
      ],
      "metadata": {
        "id": "yaQclWttYtDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def demo_advanced_features():\n",
        "    \"\"\"Demonstrate advanced Ivy features.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"PART 4: Advanced Ivy Features\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    print(\"\\nğŸ“¦ Ivy Containers - Nested Data Structures:\")\n",
        "    try:\n",
        "        ivy.set_backend('torch')\n",
        "\n",
        "        container = ivy.Container({\n",
        "            'layer1': {'weights': ivy.random_uniform(shape=(4, 8)), 'bias': ivy.zeros((8,))},\n",
        "            'layer2': {'weights': ivy.random_uniform(shape=(8, 3)), 'bias': ivy.zeros((3,))}\n",
        "        })\n",
        "\n",
        "        print(f\"   Container keys: {list(container.keys())}\")\n",
        "        print(f\"   Layer1 weight shape: {container['layer1']['weights'].shape}\")\n",
        "        print(f\"   Layer2 bias shape: {container['layer2']['bias'].shape}\")\n",
        "\n",
        "        def scale_fn(x, _):\n",
        "            return x * 2.0\n",
        "\n",
        "        scaled_container = container.cont_map(scale_fn)\n",
        "        print(f\"   âœ… Applied scaling to all tensors in container\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   âš ï¸ Container demo: {str(e)[:80]}\")\n",
        "\n",
        "    print(\"\\nğŸ”— Array API Standard Compliance:\")\n",
        "    backends_tested = []\n",
        "    for backend in ['numpy', 'torch', 'tensorflow', 'jax']:\n",
        "        try:\n",
        "            ivy.set_backend(backend)\n",
        "\n",
        "            if backend == 'jax':\n",
        "                import jax\n",
        "                jax.config.update('jax_enable_x64', True)\n",
        "\n",
        "            x = ivy.array([1.0, 2.0, 3.0])\n",
        "            y = ivy.array([4.0, 5.0, 6.0])\n",
        "\n",
        "            result = ivy.sqrt(ivy.square(x) + ivy.square(y))\n",
        "            print(f\"   {backend:12s}: L2 norm operations work âœ…\")\n",
        "            backends_tested.append(backend)\n",
        "        except Exception as e:\n",
        "            print(f\"   {backend:12s}: {str(e)[:50]}\")\n",
        "\n",
        "    print(f\"\\n   Successfully tested {len(backends_tested)} backends\")\n",
        "\n",
        "    print(\"\\nğŸ¯ Complex Multi-step Operations:\")\n",
        "    try:\n",
        "        ivy.set_backend('torch')\n",
        "\n",
        "        x = ivy.random_uniform(shape=(10, 5), low=0, high=1)\n",
        "\n",
        "        result = ivy.mean(\n",
        "            ivy.relu(\n",
        "                ivy.matmul(x, ivy.permute_dims(x, axes=(1, 0)))\n",
        "            ),\n",
        "            axis=0\n",
        "        )\n",
        "\n",
        "        print(f\"   Chained operations (matmul â†’ relu â†’ mean)\")\n",
        "        print(f\"   Input shape: (10, 5), Output shape: {result.shape}\")\n",
        "        print(f\"   âœ… Complex operation graph executed successfully\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   âš ï¸ {str(e)[:80]}\")\n",
        "\n",
        "    ivy.unset_backend()"
      ],
      "metadata": {
        "id": "PcqgMA1tYxvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def benchmark_operation(op_func, x, iterations=50):\n",
        "    \"\"\"Benchmark an operation.\"\"\"\n",
        "    start = time.time()\n",
        "    for _ in range(iterations):\n",
        "        result = op_func(x)\n",
        "    return time.time() - start\n",
        "\n",
        "\n",
        "def demo_performance():\n",
        "    \"\"\"Compare performance across backends.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"PART 5: Performance Benchmarking\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    X = np.random.randn(100, 100).astype(np.float32)\n",
        "\n",
        "    def complex_operation(x):\n",
        "        \"\"\"A more complex computation.\"\"\"\n",
        "        z = ivy.matmul(x, ivy.permute_dims(x, axes=(1, 0)))\n",
        "        z = ivy.relu(z)\n",
        "        z = ivy.mean(z, axis=0)\n",
        "        return ivy.sum(z)\n",
        "\n",
        "    print(\"\\nâ±ï¸ Benchmarking matrix operations (50 iterations):\")\n",
        "    print(\"   Operation: matmul â†’ relu â†’ mean â†’ sum\")\n",
        "\n",
        "    for backend in ['numpy', 'torch', 'tensorflow', 'jax']:\n",
        "        try:\n",
        "            ivy.set_backend(backend)\n",
        "\n",
        "            if backend == 'jax':\n",
        "                import jax\n",
        "                jax.config.update('jax_enable_x64', True)\n",
        "\n",
        "            x_ivy = ivy.array(X)\n",
        "\n",
        "            _ = complex_operation(x_ivy)\n",
        "\n",
        "            elapsed = benchmark_operation(complex_operation, x_ivy, iterations=50)\n",
        "\n",
        "            print(f\"   {backend:12s}: {elapsed:.4f}s ({elapsed/50*1000:.2f}ms per op)\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   {backend:12s}: âš ï¸ {str(e)[:60]}\")\n",
        "\n",
        "    ivy.unset_backend()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\"\"\n",
        "    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "    â•‘          Advanced Ivy Tutorial - Framework-Agnostic ML             â•‘\n",
        "    â•‘                  Write Once, Run Everywhere!                       â•‘\n",
        "    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "    \"\"\")\n",
        "\n",
        "    results = demo_framework_agnostic_network()\n",
        "    demo_transpilation()\n",
        "    demo_unified_api()\n",
        "    demo_advanced_features()\n",
        "    demo_performance()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ğŸ‰ Tutorial Complete!\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nğŸ“š Key Takeaways:\")\n",
        "    print(\"   1. Ivy enables writing ML code once that runs on any framework\")\n",
        "    print(\"   2. Same operations work identically across NumPy, PyTorch, TF, JAX\")\n",
        "    print(\"   3. Unified API provides consistent operations across backends\")\n",
        "    print(\"   4. Switch backends dynamically for optimal performance\")\n",
        "    print(\"   5. Containers help manage complex nested model structures\")\n",
        "    print(\"\\nğŸ’¡ Next Steps:\")\n",
        "    print(\"   - Build your own framework-agnostic models\")\n",
        "    print(\"   - Use ivy.Container for managing model parameters\")\n",
        "    print(\"   - Explore ivy.trace_graph() for computation graph optimization\")\n",
        "    print(\"   - Try different backends to find optimal performance\")\n",
        "    print(\"   - Check docs at: https://docs.ivy.dev/\")\n",
        "    print(\"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhsVy9Vohi3Q",
        "outputId": "f0d894a5-adb1-4408-da55-6e2bde0c1d51"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ivy version: 1.0.0.5\n",
            "\n",
            "    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
            "    â•‘          Advanced Ivy Tutorial - Framework-Agnostic ML             â•‘\n",
            "    â•‘                  Write Once, Run Everywhere!                       â•‘\n",
            "    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "    \n",
            "\n",
            "======================================================================\n",
            "PART 1: Framework-Agnostic Neural Network\n",
            "======================================================================\n",
            "\n",
            "ğŸ”„ Running with NUMPY backend...\n",
            "   Final Loss: 1.0954\n",
            "   Accuracy: 34.00%\n",
            "   Time: 1.580s\n",
            "\n",
            "ğŸ”„ Running with TORCH backend...\n",
            "   Final Loss: 1.0864\n",
            "   Accuracy: 37.00%\n",
            "   Time: 4.613s\n",
            "\n",
            "ğŸ”„ Running with TENSORFLOW backend...\n",
            "   Final Loss: 1.0713\n",
            "   Accuracy: 42.00%\n",
            "   Time: 2.774s\n",
            "\n",
            "ğŸ”„ Running with JAX backend...\n",
            "   Final Loss: 1.0878\n",
            "   Accuracy: 38.00%\n",
            "   Time: 3.323s\n",
            "\n",
            "======================================================================\n",
            "PART 2: Framework Transpilation\n",
            "======================================================================\n",
            "\n",
            "ğŸ“¦ Original PyTorch function:\n",
            "   PyTorch result: 1.423278\n",
            "\n",
            "ğŸ”„ Transpilation Demo:\n",
            "   Note: ivy.transpile() is powerful but complex.\n",
            "   It works best with traced/compiled functions.\n",
            "   For simple demonstrations, we'll show the unified API instead.\n",
            "\n",
            "âœ¨ Equivalent computation across frameworks:\n",
            "   NumPy result: 1.423278\n",
            "   TensorFlow result: 1.423278\n",
            "   JAX result: 1.423278\n",
            "\n",
            "   âœ… All results match within numerical precision!\n",
            "\n",
            "======================================================================\n",
            "PART 3: Unified API Across Frameworks\n",
            "======================================================================\n",
            "\n",
            "ğŸ”§ Matrix Multiplication:\n",
            "   numpy       : shape=(5, 5), mean=0.8369\n",
            "   torch       : shape=(5, 5), mean=0.8369\n",
            "   tensorflow  : shape=(5, 5), mean=0.8369\n",
            "   jax         : shape=(5, 5), mean=0.8369\n",
            "\n",
            "ğŸ”§ Element-wise Operations:\n",
            "   numpy       : shape=(5, 4), mean=3.6930\n",
            "   torch       : shape=(5, 4), mean=3.6930\n",
            "   tensorflow  : shape=(5, 4), mean=3.6930\n",
            "   jax         : shape=(5, 4), mean=3.6930\n",
            "\n",
            "ğŸ”§ Reductions:\n",
            "   numpy       : scalar value = -0.3083\n",
            "   torch       : scalar value = -0.3083\n",
            "   tensorflow  : scalar value = -0.3083\n",
            "   jax         : scalar value = -0.3083\n",
            "\n",
            "ğŸ”§ Neural Net Ops:\n",
            "   numpy       : scalar value = 0.5108\n",
            "   torch       : scalar value = 0.5108\n",
            "   tensorflow  : scalar value = 0.5108\n",
            "   jax         : scalar value = 0.5108\n",
            "\n",
            "ğŸ”§ Statistical Ops:\n",
            "   numpy       : scalar value = 1.2997\n",
            "   torch       : scalar value = 1.2997\n",
            "   tensorflow  : scalar value = 1.2997\n",
            "   jax         : scalar value = 1.2997\n",
            "\n",
            "ğŸ”§ Broadcasting:\n",
            "   numpy       : shape=(5, 4), mean=0.2665\n",
            "   torch       : shape=(5, 4), mean=0.2665\n",
            "   tensorflow  : shape=(5, 4), mean=0.2665\n",
            "   jax         : shape=(5, 4), mean=0.2665\n",
            "\n",
            "======================================================================\n",
            "PART 4: Advanced Ivy Features\n",
            "======================================================================\n",
            "\n",
            "ğŸ“¦ Ivy Containers - Nested Data Structures:\n",
            "   Container keys: ['layer1', 'layer2']\n",
            "   Layer1 weight shape: ivy.Shape(4, 8)\n",
            "   Layer2 bias shape: ivy.Shape(3,)\n",
            "   âœ… Applied scaling to all tensors in container\n",
            "\n",
            "ğŸ”— Array API Standard Compliance:\n",
            "   numpy       : L2 norm operations work âœ…\n",
            "   torch       : L2 norm operations work âœ…\n",
            "   tensorflow  : L2 norm operations work âœ…\n",
            "   jax         : L2 norm operations work âœ…\n",
            "\n",
            "   Successfully tested 4 backends\n",
            "\n",
            "ğŸ¯ Complex Multi-step Operations:\n",
            "   Chained operations (matmul â†’ relu â†’ mean)\n",
            "   Input shape: (10, 5), Output shape: ivy.Shape(10)\n",
            "   âœ… Complex operation graph executed successfully\n",
            "\n",
            "======================================================================\n",
            "PART 5: Performance Benchmarking\n",
            "======================================================================\n",
            "\n",
            "â±ï¸ Benchmarking matrix operations (50 iterations):\n",
            "   Operation: matmul â†’ relu â†’ mean â†’ sum\n",
            "   numpy       : 0.7470s (14.94ms per op)\n",
            "   torch       : 0.8177s (16.35ms per op)\n",
            "   tensorflow  : 0.8403s (16.81ms per op)\n",
            "   jax         : 1.3064s (26.13ms per op)\n",
            "\n",
            "======================================================================\n",
            "ğŸ‰ Tutorial Complete!\n",
            "======================================================================\n",
            "\n",
            "ğŸ“š Key Takeaways:\n",
            "   1. Ivy enables writing ML code once that runs on any framework\n",
            "   2. Same operations work identically across NumPy, PyTorch, TF, JAX\n",
            "   3. Unified API provides consistent operations across backends\n",
            "   4. Switch backends dynamically for optimal performance\n",
            "   5. Containers help manage complex nested model structures\n",
            "\n",
            "ğŸ’¡ Next Steps:\n",
            "   - Build your own framework-agnostic models\n",
            "   - Use ivy.Container for managing model parameters\n",
            "   - Explore ivy.trace_graph() for computation graph optimization\n",
            "   - Try different backends to find optimal performance\n",
            "   - Check docs at: https://docs.ivy.dev/\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DbScqH6anTH4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}