{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import sys, subprocess, textwrap, math, time\n",
        "\n",
        "def pip_install(pkg: str):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
        "\n",
        "pip_install(\"einops\")\n",
        "pip_install(\"torch\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from einops import rearrange, reduce, repeat, einsum, pack, unpack\n",
        "from einops.layers.torch import Rearrange, Reduce\n",
        "\n",
        "torch.manual_seed(0)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "def section(title: str):\n",
        "    print(\"\\n\" + \"=\" * 90)\n",
        "    print(title)\n",
        "    print(\"=\" * 90)\n",
        "\n",
        "def show_shape(name, x):\n",
        "    print(f\"{name:>18} shape = {tuple(x.shape)}  dtype={x.dtype}  device={x.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jX9ZX5gzbp7",
        "outputId": "6502e929-9fb3-4ecf-8e01-5a678e7e7d5c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "section(\"1) rearrange\")\n",
        "x = torch.randn(2, 3, 4, 5, device=device)\n",
        "show_shape(\"x\", x)\n",
        "\n",
        "x_bhwc = rearrange(x, \"b c h w -> b h w c\")\n",
        "show_shape(\"x_bhwc\", x_bhwc)\n",
        "\n",
        "x_split = rearrange(x, \"b (g cg) h w -> b g cg h w\", g=3)\n",
        "show_shape(\"x_split\", x_split)\n",
        "\n",
        "x_tokens = rearrange(x, \"b c h w -> b (h w) c\")\n",
        "show_shape(\"x_tokens\", x_tokens)\n",
        "\n",
        "y = torch.randn(2, 7, 11, 13, 17, device=device)\n",
        "y2 = rearrange(y, \"b ... c -> b c ...\")\n",
        "show_shape(\"y\", y)\n",
        "show_shape(\"y2\", y2)\n",
        "\n",
        "try:\n",
        "    _ = rearrange(torch.randn(2, 10, device=device), \"b (h w) -> b h w\", h=3)\n",
        "except Exception as e:\n",
        "    print(\"Expected error (shape mismatch):\", type(e).__name__, \"-\", str(e)[:140])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZmmCerXzbe7",
        "outputId": "b564e763-8855-4957-969e-21c0aa86bed9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==========================================================================================\n",
            "1) rearrange\n",
            "==========================================================================================\n",
            "                 x shape = (2, 3, 4, 5)  dtype=torch.float32  device=cpu\n",
            "            x_bhwc shape = (2, 4, 5, 3)  dtype=torch.float32  device=cpu\n",
            "           x_split shape = (2, 3, 1, 4, 5)  dtype=torch.float32  device=cpu\n",
            "          x_tokens shape = (2, 20, 3)  dtype=torch.float32  device=cpu\n",
            "                 y shape = (2, 7, 11, 13, 17)  dtype=torch.float32  device=cpu\n",
            "                y2 shape = (2, 17, 7, 11, 13)  dtype=torch.float32  device=cpu\n",
            "Expected error (shape mismatch): EinopsError -  Error while processing rearrange-reduction pattern \"b (h w) -> b h w\".\n",
            " Input tensor shape: torch.Size([2, 10]). Additional info: {'h': 3}.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "section(\"2) reduce\")\n",
        "imgs = torch.randn(8, 3, 64, 64, device=device)\n",
        "show_shape(\"imgs\", imgs)\n",
        "\n",
        "gap = reduce(imgs, \"b c h w -> b c\", \"mean\")\n",
        "show_shape(\"gap\", gap)\n",
        "\n",
        "pooled = reduce(imgs, \"b c (h ph) (w pw) -> b c h w\", \"mean\", ph=2, pw=2)\n",
        "show_shape(\"pooled\", pooled)\n",
        "\n",
        "chmax = reduce(imgs, \"b c h w -> b c\", \"max\")\n",
        "show_shape(\"chmax\", chmax)\n",
        "\n",
        "section(\"3) repeat\")\n",
        "vec = torch.randn(5, device=device)\n",
        "show_shape(\"vec\", vec)\n",
        "\n",
        "vec_batched = repeat(vec, \"d -> b d\", b=4)\n",
        "show_shape(\"vec_batched\", vec_batched)\n",
        "\n",
        "q = torch.randn(2, 32, device=device)\n",
        "q_heads = repeat(q, \"b d -> b heads d\", heads=8)\n",
        "show_shape(\"q_heads\", q_heads)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lo4v0UJuzbc5",
        "outputId": "0d88568d-e8f2-4dc3-c016-c968774d85de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==========================================================================================\n",
            "2) reduce\n",
            "==========================================================================================\n",
            "              imgs shape = (8, 3, 64, 64)  dtype=torch.float32  device=cpu\n",
            "               gap shape = (8, 3)  dtype=torch.float32  device=cpu\n",
            "            pooled shape = (8, 3, 32, 32)  dtype=torch.float32  device=cpu\n",
            "             chmax shape = (8, 3)  dtype=torch.float32  device=cpu\n",
            "\n",
            "==========================================================================================\n",
            "3) repeat\n",
            "==========================================================================================\n",
            "               vec shape = (5,)  dtype=torch.float32  device=cpu\n",
            "       vec_batched shape = (4, 5)  dtype=torch.float32  device=cpu\n",
            "           q_heads shape = (2, 8, 32)  dtype=torch.float32  device=cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "section(\"4) patchify\")\n",
        "B, C, H, W = 4, 3, 32, 32\n",
        "P = 8\n",
        "img = torch.randn(B, C, H, W, device=device)\n",
        "show_shape(\"img\", img)\n",
        "\n",
        "patches = rearrange(img, \"b c (h p1) (w p2) -> b (h w) (p1 p2 c)\", p1=P, p2=P)\n",
        "show_shape(\"patches\", patches)\n",
        "\n",
        "img_rec = rearrange(\n",
        "    patches,\n",
        "    \"b (h w) (p1 p2 c) -> b c (h p1) (w p2)\",\n",
        "    h=H // P,\n",
        "    w=W // P,\n",
        "    p1=P,\n",
        "    p2=P,\n",
        "    c=C,\n",
        ")\n",
        "show_shape(\"img_rec\", img_rec)\n",
        "\n",
        "max_err = (img - img_rec).abs().max().item()\n",
        "print(\"Reconstruction max abs error:\", max_err)\n",
        "assert max_err < 1e-6\n",
        "\n",
        "section(\"5) attention\")\n",
        "B, T, D = 2, 64, 256\n",
        "Hh = 8\n",
        "Dh = D // Hh\n",
        "x = torch.randn(B, T, D, device=device)\n",
        "show_shape(\"x\", x)\n",
        "\n",
        "proj = nn.Linear(D, 3 * D, bias=False).to(device)\n",
        "qkv = proj(x)\n",
        "show_shape(\"qkv\", qkv)\n",
        "\n",
        "q, k, v = rearrange(qkv, \"b t (three heads dh) -> three b heads t dh\", three=3, heads=Hh, dh=Dh)\n",
        "show_shape(\"q\", q)\n",
        "show_shape(\"k\", k)\n",
        "show_shape(\"v\", v)\n",
        "\n",
        "scale = Dh ** -0.5\n",
        "attn_logits = einsum(q, k, \"b h t dh, b h s dh -> b h t s\") * scale\n",
        "show_shape(\"attn_logits\", attn_logits)\n",
        "\n",
        "attn = attn_logits.softmax(dim=-1)\n",
        "show_shape(\"attn\", attn)\n",
        "\n",
        "out = einsum(attn, v, \"b h t s, b h s dh -> b h t dh\")\n",
        "show_shape(\"out (per-head)\", out)\n",
        "\n",
        "out_merged = rearrange(out, \"b h t dh -> b t (h dh)\")\n",
        "show_shape(\"out_merged\", out_merged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qplgFXqWzbaf",
        "outputId": "91ccd178-e700-4161-906f-e1f021240f58"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==========================================================================================\n",
            "4) patchify\n",
            "==========================================================================================\n",
            "               img shape = (4, 3, 32, 32)  dtype=torch.float32  device=cpu\n",
            "           patches shape = (4, 16, 192)  dtype=torch.float32  device=cpu\n",
            "           img_rec shape = (4, 3, 32, 32)  dtype=torch.float32  device=cpu\n",
            "Reconstruction max abs error: 0.0\n",
            "\n",
            "==========================================================================================\n",
            "5) attention\n",
            "==========================================================================================\n",
            "                 x shape = (2, 64, 256)  dtype=torch.float32  device=cpu\n",
            "               qkv shape = (2, 64, 768)  dtype=torch.float32  device=cpu\n",
            "                 q shape = (2, 8, 64, 32)  dtype=torch.float32  device=cpu\n",
            "                 k shape = (2, 8, 64, 32)  dtype=torch.float32  device=cpu\n",
            "                 v shape = (2, 8, 64, 32)  dtype=torch.float32  device=cpu\n",
            "       attn_logits shape = (2, 8, 64, 64)  dtype=torch.float32  device=cpu\n",
            "              attn shape = (2, 8, 64, 64)  dtype=torch.float32  device=cpu\n",
            "    out (per-head) shape = (2, 8, 64, 32)  dtype=torch.float32  device=cpu\n",
            "        out_merged shape = (2, 64, 256)  dtype=torch.float32  device=cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "section(\"6) pack unpack\")\n",
        "B, Cemb = 2, 128\n",
        "\n",
        "class_token = torch.randn(B, 1, Cemb, device=device)\n",
        "image_tokens = torch.randn(B, 196, Cemb, device=device)\n",
        "text_tokens = torch.randn(B, 32, Cemb, device=device)\n",
        "show_shape(\"class_token\", class_token)\n",
        "show_shape(\"image_tokens\", image_tokens)\n",
        "show_shape(\"text_tokens\", text_tokens)\n",
        "\n",
        "packed, ps = pack([class_token, image_tokens, text_tokens], \"b * c\")\n",
        "show_shape(\"packed\", packed)\n",
        "print(\"packed_shapes (ps):\", ps)\n",
        "\n",
        "mixer = nn.Sequential(\n",
        "    nn.LayerNorm(Cemb),\n",
        "    nn.Linear(Cemb, 4 * Cemb),\n",
        "    nn.GELU(),\n",
        "    nn.Linear(4 * Cemb, Cemb),\n",
        ").to(device)\n",
        "\n",
        "mixed = mixer(packed)\n",
        "show_shape(\"mixed\", mixed)\n",
        "\n",
        "class_out, image_out, text_out = unpack(mixed, ps, \"b * c\")\n",
        "show_shape(\"class_out\", class_out)\n",
        "show_shape(\"image_out\", image_out)\n",
        "show_shape(\"text_out\", text_out)\n",
        "assert class_out.shape == class_token.shape\n",
        "assert image_out.shape == image_tokens.shape\n",
        "assert text_out.shape == text_tokens.shape\n",
        "\n",
        "section(\"7) layers\")\n",
        "class PatchEmbed(nn.Module):\n",
        "    def __init__(self, in_channels=3, emb_dim=192, patch=8):\n",
        "        super().__init__()\n",
        "        self.patch = patch\n",
        "        self.to_patches = Rearrange(\"b c (h p1) (w p2) -> b (h w) (p1 p2 c)\", p1=patch, p2=patch)\n",
        "        self.proj = nn.Linear(in_channels * patch * patch, emb_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.to_patches(x)\n",
        "        return self.proj(x)\n",
        "\n",
        "class SimpleVisionHead(nn.Module):\n",
        "    def __init__(self, emb_dim=192, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.pool = Reduce(\"b t c -> b c\", reduction=\"mean\")\n",
        "        self.classifier = nn.Linear(emb_dim, num_classes)\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        x = self.pool(tokens)\n",
        "        return self.classifier(x)\n",
        "\n",
        "patch_embed = PatchEmbed(in_channels=3, emb_dim=192, patch=8).to(device)\n",
        "head = SimpleVisionHead(emb_dim=192, num_classes=10).to(device)\n",
        "\n",
        "imgs = torch.randn(4, 3, 32, 32, device=device)\n",
        "tokens = patch_embed(imgs)\n",
        "logits = head(tokens)\n",
        "show_shape(\"tokens\", tokens)\n",
        "show_shape(\"logits\", logits)\n",
        "\n",
        "section(\"8) practical\")\n",
        "x = torch.randn(2, 32, 16, 16, device=device)\n",
        "g = 8\n",
        "xg = rearrange(x, \"b (g cg) h w -> (b g) cg h w\", g=g)\n",
        "show_shape(\"x\", x)\n",
        "show_shape(\"xg\", xg)\n",
        "\n",
        "mean = reduce(xg, \"bg cg h w -> bg 1 1 1\", \"mean\")\n",
        "var = reduce((xg - mean) ** 2, \"bg cg h w -> bg 1 1 1\", \"mean\")\n",
        "xg_norm = (xg - mean) / torch.sqrt(var + 1e-5)\n",
        "x_norm = rearrange(xg_norm, \"(b g) cg h w -> b (g cg) h w\", b=2, g=g)\n",
        "show_shape(\"x_norm\", x_norm)\n",
        "\n",
        "z = torch.randn(3, 64, 20, 30, device=device)\n",
        "z_flat = rearrange(z, \"b c h w -> b c (h w)\")\n",
        "z_unflat = rearrange(z_flat, \"b c (h w) -> b c h w\", h=20, w=30)\n",
        "assert (z - z_unflat).abs().max().item() < 1e-6\n",
        "show_shape(\"z_flat\", z_flat)\n",
        "\n",
        "section(\"9) views\")\n",
        "a = torch.randn(2, 3, 4, 5, device=device)\n",
        "b = rearrange(a, \"b c h w -> b h w c\")\n",
        "print(\"a.is_contiguous():\", a.is_contiguous())\n",
        "print(\"b.is_contiguous():\", b.is_contiguous())\n",
        "print(\"b._base is a:\", getattr(b, \"_base\", None) is a)\n",
        "\n",
        "section(\"Done ✅ You now have reusable einops patterns for vision, attention, and multimodal token packing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxVeqvmazbYI",
        "outputId": "4ffcb139-2d4a-4037-d397-4a772a201570"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==========================================================================================\n",
            "6) pack unpack\n",
            "==========================================================================================\n",
            "       class_token shape = (2, 1, 128)  dtype=torch.float32  device=cpu\n",
            "      image_tokens shape = (2, 196, 128)  dtype=torch.float32  device=cpu\n",
            "       text_tokens shape = (2, 32, 128)  dtype=torch.float32  device=cpu\n",
            "            packed shape = (2, 229, 128)  dtype=torch.float32  device=cpu\n",
            "packed_shapes (ps): [torch.Size([1]), torch.Size([196]), torch.Size([32])]\n",
            "             mixed shape = (2, 229, 128)  dtype=torch.float32  device=cpu\n",
            "         class_out shape = (2, 1, 128)  dtype=torch.float32  device=cpu\n",
            "         image_out shape = (2, 196, 128)  dtype=torch.float32  device=cpu\n",
            "          text_out shape = (2, 32, 128)  dtype=torch.float32  device=cpu\n",
            "\n",
            "==========================================================================================\n",
            "7) layers\n",
            "==========================================================================================\n",
            "            tokens shape = (4, 16, 192)  dtype=torch.float32  device=cpu\n",
            "            logits shape = (4, 10)  dtype=torch.float32  device=cpu\n",
            "\n",
            "==========================================================================================\n",
            "8) practical\n",
            "==========================================================================================\n",
            "                 x shape = (2, 32, 16, 16)  dtype=torch.float32  device=cpu\n",
            "                xg shape = (16, 4, 16, 16)  dtype=torch.float32  device=cpu\n",
            "            x_norm shape = (2, 32, 16, 16)  dtype=torch.float32  device=cpu\n",
            "            z_flat shape = (3, 64, 600)  dtype=torch.float32  device=cpu\n",
            "\n",
            "==========================================================================================\n",
            "9) views\n",
            "==========================================================================================\n",
            "a.is_contiguous(): True\n",
            "b.is_contiguous(): False\n",
            "b._base is a: True\n",
            "\n",
            "==========================================================================================\n",
            "Done ✅ You now have reusable einops patterns for vision, attention, and multimodal token packing\n",
            "==========================================================================================\n"
          ]
        }
      ]
    }
  ]
}