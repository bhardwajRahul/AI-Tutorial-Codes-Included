{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syZ3Lp70igIy"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "os.environ['OPENAI_API_KEY'] = getpass('Enter OpenAI API Key: ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1qmgGKrjBRm",
        "outputId": "bdbc2f2b-6a03-45fb-c0c1-2dabdaa805b4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter OpenAI API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Direct Prompt"
      ],
      "metadata": {
        "id": "MCeHp8S4G_s_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "for i in range(5):\n",
        "    response = client.responses.create(\n",
        "        model=\"gpt-5.2\",\n",
        "        input=\"Tell me a joke about coffee\"\n",
        "    )\n",
        "\n",
        "    print(f\"\\nResponse {i+1}:\\n\")\n",
        "    print(response.output_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Fk20KnsFQJv",
        "outputId": "1177bfce-5139-4cf7-faa2-b9613ba00740"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Response 1:\n",
            "\n",
            "Why did the coffee file a police report?  \n",
            "It got mugged.\n",
            "\n",
            "Response 2:\n",
            "\n",
            "Why did the coffee file a police report?  \n",
            "It got mugged.\n",
            "\n",
            "Response 3:\n",
            "\n",
            "I tried to make a joke about coffee… but it espresso-ly came out weak.\n",
            "\n",
            "Response 4:\n",
            "\n",
            "I tried to make a joke about coffee… but it got *filtered*.\n",
            "\n",
            "Response 5:\n",
            "\n",
            "Why did the coffee file a police report?  \n",
            "It got mugged.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verbalized Sampling"
      ],
      "metadata": {
        "id": "jvB5k7YqG9UW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "vs_prompt = \"\"\"\n",
        "Generate 5 different responses with their corresponding probabilities.\n",
        "Then sample one response according to those probabilities.\n",
        "\n",
        "Task: Tell me a joke about coffee\n",
        "\"\"\"\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-5.2\",\n",
        "    input=vs_prompt\n",
        ")\n",
        "\n",
        "print(\"Verbalized Sampling Output:\\n\")\n",
        "print(response.output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy3aHCx1jSMT",
        "outputId": "fea05057-0720-469f-9b22-ffd7f5ee2a33"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verbalized Sampling Output:\n",
            "\n",
            "1) **Response (p=0.22):**  \n",
            "Why did the coffee file a police report? It got **mugged**.\n",
            "\n",
            "2) **Response (p=0.20):**  \n",
            "I like my coffee like I like my mornings: **dark**, and way too **early**.\n",
            "\n",
            "3) **Response (p=0.19):**  \n",
            "What do you call sad coffee? **Depresso**.\n",
            "\n",
            "4) **Response (p=0.21):**  \n",
            "Decaf coffee is just a cup of coffee that’s been through a lot and lost the will to live.\n",
            "\n",
            "5) **Response (p=0.18):**  \n",
            "My coffee and I have a lot in common: we’re both **grounded** until things heat up.\n",
            "\n",
            "**Sampled response (according to the probabilities):**  \n",
            "What do you call sad coffee? **Depresso**.\n"
          ]
        }
      ]
    }
  ]
}