{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os, time, math, json, random\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Dict, Optional, Tuple, Any\n",
        "from getpass import getpass\n",
        "\n",
        "USE_OPENAI = True\n",
        "\n",
        "if USE_OPENAI:\n",
        "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "        os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OPENAI_API_KEY (hidden): \").strip()\n",
        "    try:\n",
        "        from openai import OpenAI\n",
        "        client = OpenAI()\n",
        "    except Exception as e:\n",
        "        print(\"OpenAI SDK import failed. Falling back to offline mode.\\nError:\", e)\n",
        "        USE_OPENAI = False"
      ],
      "metadata": {
        "id": "OE9Atp1qfURo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def approx_tokens(text: str) -> int:\n",
        "    return max(1, math.ceil(len(text) / 4))\n",
        "\n",
        "@dataclass\n",
        "class Budget:\n",
        "    max_tokens: int\n",
        "    max_latency_ms: int\n",
        "    max_tool_calls: int\n",
        "\n",
        "@dataclass\n",
        "class Spend:\n",
        "    tokens: int = 0\n",
        "    latency_ms: int = 0\n",
        "    tool_calls: int = 0\n",
        "\n",
        "    def within(self, b: Budget) -> bool:\n",
        "        return (self.tokens <= b.max_tokens and\n",
        "                self.latency_ms <= b.max_latency_ms and\n",
        "                self.tool_calls <= b.max_tool_calls)\n",
        "\n",
        "    def add(self, other: \"Spend\") -> \"Spend\":\n",
        "        return Spend(\n",
        "            tokens=self.tokens + other.tokens,\n",
        "            latency_ms=self.latency_ms + other.latency_ms,\n",
        "            tool_calls=self.tool_calls + other.tool_calls\n",
        "        )"
      ],
      "metadata": {
        "id": "bZPtenAMfUCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class StepOption:\n",
        "    name: str\n",
        "    description: str\n",
        "    est_spend: Spend\n",
        "    est_value: float\n",
        "    executor: str\n",
        "    payload: Dict[str, Any] = field(default_factory=dict)\n",
        "\n",
        "@dataclass\n",
        "class PlanCandidate:\n",
        "    steps: List[StepOption]\n",
        "    spend: Spend\n",
        "    value: float\n",
        "    rationale: str = \"\"\n",
        "\n",
        "def llm_text(prompt: str, *, model: str = \"gpt-5\", effort: str = \"low\") -> str:\n",
        "    if not USE_OPENAI:\n",
        "        return \"\"\n",
        "    t0 = time.time()\n",
        "    resp = client.responses.create(\n",
        "        model=model,\n",
        "        reasoning={\"effort\": effort},\n",
        "        input=prompt,\n",
        "    )\n",
        "    _ = (time.time() - t0)\n",
        "    return resp.output_text or \"\""
      ],
      "metadata": {
        "id": "vJC9UJ0wfT_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_step_options(task: str) -> List[StepOption]:\n",
        "    base = [\n",
        "        StepOption(\n",
        "            name=\"Clarify deliverables (local)\",\n",
        "            description=\"Extract deliverable checklist + acceptance criteria from the task.\",\n",
        "            est_spend=Spend(tokens=60, latency_ms=20, tool_calls=0),\n",
        "            est_value=6.0,\n",
        "            executor=\"local\",\n",
        "        ),\n",
        "        StepOption(\n",
        "            name=\"Outline plan (LLM)\",\n",
        "            description=\"Create a structured outline with sections, constraints, and assumptions.\",\n",
        "            est_spend=Spend(tokens=600, latency_ms=1200, tool_calls=1),\n",
        "            est_value=10.0,\n",
        "            executor=\"llm\",\n",
        "            payload={\"prompt_kind\":\"outline\"}\n",
        "        ),\n",
        "        StepOption(\n",
        "            name=\"Outline plan (local)\",\n",
        "            description=\"Create a rough outline using templates (no LLM).\",\n",
        "            est_spend=Spend(tokens=120, latency_ms=40, tool_calls=0),\n",
        "            est_value=5.5,\n",
        "            executor=\"local\",\n",
        "        ),\n",
        "        StepOption(\n",
        "            name=\"Risk register (LLM)\",\n",
        "            description=\"Generate risks, mitigations, owners, and severity.\",\n",
        "            est_spend=Spend(tokens=700, latency_ms=1400, tool_calls=1),\n",
        "            est_value=9.0,\n",
        "            executor=\"llm\",\n",
        "            payload={\"prompt_kind\":\"risks\"}\n",
        "        ),\n",
        "        StepOption(\n",
        "            name=\"Risk register (local)\",\n",
        "            description=\"Generate a standard risk register from a reusable template.\",\n",
        "            est_spend=Spend(tokens=160, latency_ms=60, tool_calls=0),\n",
        "            est_value=5.0,\n",
        "            executor=\"local\",\n",
        "        ),\n",
        "        StepOption(\n",
        "            name=\"Timeline (LLM)\",\n",
        "            description=\"Draft a realistic milestone timeline with dependencies.\",\n",
        "            est_spend=Spend(tokens=650, latency_ms=1300, tool_calls=1),\n",
        "            est_value=8.5,\n",
        "            executor=\"llm\",\n",
        "            payload={\"prompt_kind\":\"timeline\"}\n",
        "        ),\n",
        "        StepOption(\n",
        "            name=\"Timeline (local)\",\n",
        "            description=\"Draft a simple timeline from a generic milestone template.\",\n",
        "            est_spend=Spend(tokens=150, latency_ms=60, tool_calls=0),\n",
        "            est_value=4.8,\n",
        "            executor=\"local\",\n",
        "        ),\n",
        "        StepOption(\n",
        "            name=\"Quality pass (LLM)\",\n",
        "            description=\"Rewrite for clarity, consistency, and formatting.\",\n",
        "            est_spend=Spend(tokens=900, latency_ms=1600, tool_calls=1),\n",
        "            est_value=8.0,\n",
        "            executor=\"llm\",\n",
        "            payload={\"prompt_kind\":\"polish\"}\n",
        "        ),\n",
        "        StepOption(\n",
        "            name=\"Quality pass (local)\",\n",
        "            description=\"Light formatting + consistency checks without LLM.\",\n",
        "            est_spend=Spend(tokens=120, latency_ms=50, tool_calls=0),\n",
        "            est_value=3.5,\n",
        "            executor=\"local\",\n",
        "        ),\n",
        "    ]\n",
        "\n",
        "    if USE_OPENAI:\n",
        "        meta_prompt = f\"\"\"\n",
        "You are a planning assistant. For the task below, propose 3-5 OPTIONAL extra steps that improve quality,\n",
        "like checks, validations, or stakeholder tailoring. Keep each step short.\n",
        "\n",
        "TASK:\n",
        "{task}\n",
        "\n",
        "Return JSON list with fields: name, description, est_value(1-10).\n",
        "\"\"\"\n",
        "        txt = llm_text(meta_prompt, model=\"gpt-5\", effort=\"low\")\n",
        "        try:\n",
        "            items = json.loads(txt.strip())\n",
        "            for it in items[:5]:\n",
        "                base.append(\n",
        "                    StepOption(\n",
        "                        name=str(it.get(\"name\",\"Extra step (local)\"))[:60],\n",
        "                        description=str(it.get(\"description\",\"\"))[:200],\n",
        "                        est_spend=Spend(tokens=120, latency_ms=60, tool_calls=0),\n",
        "                        est_value=float(it.get(\"est_value\", 5.0)),\n",
        "                        executor=\"local\",\n",
        "                    )\n",
        "                )\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    return base"
      ],
      "metadata": {
        "id": "rY9BUhybfT9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plan_under_budget(\n",
        "    options: List[StepOption],\n",
        "    budget: Budget,\n",
        "    *,\n",
        "    max_steps: int = 6,\n",
        "    beam_width: int = 12,\n",
        "    diversity_penalty: float = 0.2\n",
        ") -> PlanCandidate:\n",
        "    def redundancy_cost(chosen: List[StepOption], new: StepOption) -> float:\n",
        "        key_new = new.name.split(\"(\")[0].strip().lower()\n",
        "        overlap = 0\n",
        "        for s in chosen:\n",
        "            key_s = s.name.split(\"(\")[0].strip().lower()\n",
        "            if key_s == key_new:\n",
        "                overlap += 1\n",
        "        return overlap * diversity_penalty\n",
        "\n",
        "    beams: List[PlanCandidate] = [PlanCandidate(steps=[], spend=Spend(), value=0.0, rationale=\"\")]\n",
        "\n",
        "    for _ in range(max_steps):\n",
        "        expanded: List[PlanCandidate] = []\n",
        "        for cand in beams:\n",
        "            for opt in options:\n",
        "                if opt in cand.steps:\n",
        "                    continue\n",
        "                new_spend = cand.spend.add(opt.est_spend)\n",
        "                if not new_spend.within(budget):\n",
        "                    continue\n",
        "                new_value = cand.value + opt.est_value - redundancy_cost(cand.steps, opt)\n",
        "                expanded.append(\n",
        "                    PlanCandidate(\n",
        "                        steps=cand.steps + [opt],\n",
        "                        spend=new_spend,\n",
        "                        value=new_value,\n",
        "                        rationale=cand.rationale\n",
        "                    )\n",
        "                )\n",
        "        if not expanded:\n",
        "            break\n",
        "        expanded.sort(key=lambda c: c.value, reverse=True)\n",
        "        beams = expanded[:beam_width]\n",
        "\n",
        "    best = max(beams, key=lambda c: c.value)\n",
        "    return best"
      ],
      "metadata": {
        "id": "oOCumnDVfT7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNsxZxXIdu8U",
        "outputId": "293912ec-ddf8-43a6-976a-d1c3c4ef6310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter OPENAI_API_KEY (hidden): ··········\n",
            "=== SELECTED PLAN (budget-aware) ===\n",
            "- Outline plan (LLM) | est_spend=Spend(tokens=600, latency_ms=1200, tool_calls=1) | est_value=10.0\n",
            "- Data Quality & Integration Check | est_spend=Spend(tokens=120, latency_ms=60, tool_calls=0) | est_value=10.0\n",
            "- Risk register (LLM) | est_spend=Spend(tokens=700, latency_ms=1400, tool_calls=1) | est_value=9.0\n",
            "- Stakeholder Alignment Interviews | est_spend=Spend(tokens=120, latency_ms=60, tool_calls=0) | est_value=9.0\n",
            "- KPI & Baseline Definition | est_spend=Spend(tokens=120, latency_ms=60, tool_calls=0) | est_value=9.0\n",
            "- Pilot UAT & Iteration Loop | est_spend=Spend(tokens=120, latency_ms=60, tool_calls=0) | est_value=9.0\n",
            "\n",
            "Estimated spend: Spend(tokens=1780, latency_ms=2840, tool_calls=2)\n",
            "Budget: Budget(max_tokens=2200, max_latency_ms=3500, max_tool_calls=2)\n",
            "\n",
            "=== EXECUTING PLAN ===\n",
            "\n",
            "=== OUTPUT DRAFT ===\n",
            "\n",
            "### Step 1: Outline plan (LLM)\n",
            "1. Title and Executive Summary\n",
            "   1.1 Project name: Logistics Dashboard & Fleet Optimization Pilot\n",
            "   1.2 One-sentence objective and expected impact\n",
            "   1.3 Pilot duration and key outcomes at a glance\n",
            "\n",
            "2. Problem Statement and Business Context\n",
            "   2.1 Current logistics challenges (visibility, cost, on-time performance)\n",
            "   2.2 Why now (market/customer pressures, growth, cost targets)\n",
            "   2.3 Strategic alignment with company goals\n",
            "\n",
            "3. Objectives and Success Criteria\n",
            "   3.1 Objectives (visibility, efficiency, cost/service optimization)\n",
            "   3.2 Quantified KPIs (e.g., on-time +5–10%, empty miles −5–8%, cost/stop −3–7%, SLA adherence +5%)\n",
            "   3.3 Qualitative outcomes (decision speed, exception management)\n",
            "\n",
            "4. Scope\n",
            "   4.1 In-scope\n",
            "       - Pilot regions/routes, fleet types (owned/3PL), and time window\n",
            "       - Features: real-time dashboard, alerts, route optimization, load consolidation, driver/asset utilization\n",
            "       - Data sources: TMS, WMS, telematics/GPS, ERP orders, fuel, traffic/weather\n",
            "   4.2 Out-of-scope\n",
            "       - Network redesign, pricing renegotiations, hardware procurement beyond pilot needs, enterprise roll-out\n",
            "\n",
            "5. Deliverables\n",
            "   5.1 Pilot dashboard (KPIs, heatmaps, lane performance, exceptions)\n",
            "   5.2 Optimization engine configurations (constraints, objectives)\n",
            "   5.3 Integration connectors and data model\n",
            "   5.4 Playbooks: dispatch workflows, exception handling, daily/weekly ops cadence\n",
            "   5.5 Pilot report: results, ROI, scale recommendation\n",
            "\n",
            "6. Solution Overview\n",
            "   6.1 Architecture (data ingest, storage, processing, analytics, visualization)\n",
            "   6.2 Optimization approach (heuristics/MILP; constraints: capacity, time windows, driver hours)\n",
            "   6.3 User profiles and UX (dispatcher, planner, ops leader)\n",
            "   6.4 Alerting & automation (SLA breach, late pickup, route deviation)\n",
            "\n",
            "7. Stakeholders and Roles\n",
            "   7.1 Sponsor, product owner, operations lead, planners/dispatchers, IT/data engineering, data science, security/compliance\n",
            "   7.2 RACI summary for decisions and sign-offs\n",
            "\n",
            "8. Assumptions and Dependencies\n",
            "   8.1 Data availability/quality, API access, telematics coverage\n",
            "   8.2 SME availability for requirements and UAT\n",
            "   8.3 Change management support and training time\n",
            "\n",
            "9. Timeline and Milestones (8–12 weeks)\n",
            "   9.1 Week 1–2: Requirements, data audit, success metric baselining\n",
            "   9.2 Week 3–4: Data integration, prototype dashboard v1\n",
            "   9.3 Week 5–6: Optimization engine configuration, scenarios, dashboard v2\n",
            "   9.4 Week 7: UAT, training, go-live for pilot lanes\n",
            "   9.5 Week 8–10: Pilot run, monitoring, iterations\n",
            "   9.6 Week 11–12: Results analysis, ROI, scale plan\n",
            "\n",
            "10. Budget and Resources\n",
            "    10.1 Effort by role (FTE-weeks) and tool/licensing costs\n",
            "    10.2 Cloud/compute estimates for pilot\n",
            "    10.3 Contingency allocation\n",
            "\n",
            "11. Data Privacy, Security, and Compliance\n",
            "    11.1 Data classification, retention, and PII handling\n",
            "    11.2 Access controls, audit logs, encryption\n",
            "    11.3 Vendor and 3rd-party data sharing considerations\n",
            "\n",
            "12. Change Management and Training\n",
            "    12.1 Training sessions and materials\n",
            "    12.2 Pilot operating cadence and feedback loop\n",
            "    12.3 Adoption metrics\n",
            "\n",
            "13. Test Plan and Acceptance Criteria\n",
            "    13.1 Functional and data quality tests\n",
            "    13.2 Performance and latency thresholds\n",
            "    13.3 Go/no-go criteria tied to KPIs\n",
            "\n",
            "14. Risks and Mitigations\n",
            "    14.1 Data quality gaps or latency → data cleansing, SLAs, fallbacks\n",
            "    14.2 User adoption resistance → early champion engagement, training\n",
            "    14.3 Optimization infeasibility under real constraints → scenario tuning, manual override\n",
            "    14.4 Integration delays → phased connectors, mock data\n",
            "    14.5 Scope creep → change control process\n",
            "\n",
            "15. Post-Pilot Scale Plan\n",
            "    15.1 Scale criteria and roadmap (regions, fleets, features)\n",
            "    15.2 Governance and ongoing ownership\n",
            "    15.3 Expected ROI at scale and investment needs\n",
            "\n",
            "\n",
            "### Step 2: Data Quality & Integration Check\n",
            "Completed: Data Quality & Integration Check\n",
            "\n",
            "\n",
            "\n",
            "### Step 3: Risk register (LLM)\n",
            "Here’s a risk register for drafting the 1-page proposal.\n",
            "\n",
            "- Risk: Unclear objectives or success criteria\n",
            "  Impact: High — proposal may miss decision needs\n",
            "  Likelihood: Medium\n",
            "  Mitigation: 30-minute kickoff to confirm goals, audience, success metrics\n",
            "  Owner: Proposal Lead\n",
            "\n",
            "- Risk: Stakeholder misalignment (Ops, Product, Finance)\n",
            "  Impact: High — rework, delays\n",
            "  Likelihood: Medium\n",
            "  Mitigation: Circulate a 1-paragraph outline for sign-off before full draft\n",
            "  Owner: Product Manager\n",
            "\n",
            "- Risk: Missing inputs for scope (data sources, KPIs, constraints)\n",
            "  Impact: High — vague or infeasible scope\n",
            "  Likelihood: Medium\n",
            "  Mitigation: Create an inputs checklist; schedule SME touchpoints; capture assumptions\n",
            "  Owner: Operations SME\n",
            "\n",
            "- Risk: Unvalidated timeline assumptions (dependencies, approvals)\n",
            "  Impact: Medium — unrealistic plan\n",
            "  Likelihood: Medium\n",
            "  Mitigation: Draft timeline with buffer; confirm key dependencies with owners\n",
            "  Owner: Project Manager (PMO)\n",
            "\n",
            "- Risk: Data availability unknown for pilot (access, quality, latency)\n",
            "  Impact: High — scope/timeline not credible\n",
            "  Likelihood: Medium\n",
            "  Mitigation: Quick feasibility ping with Data Eng; include data-readiness gate in risks\n",
            "  Owner: Data Engineer\n",
            "\n",
            "- Risk: Overly technical or too high-level for exec audience\n",
            "  Impact: Medium — low buy-in\n",
            "  Likelihood: Medium\n",
            "  Mitigation: Use exec-summary first; apply BLUF; peer review for clarity\n",
            "  Owner: Proposal Lead\n",
            "\n",
            "- Risk: Length exceeds 1 page\n",
            "  Impact: Medium — reviewers disengage\n",
            "  Likelihood: Medium\n",
            "  Mitigation: Enforce word/character budget; move detail to appendix links\n",
            "  Owner: Proposal Lead\n",
            "\n",
            "- Risk: Review bottlenecks and slow feedback\n",
            "  Impact: Medium — missed deadline\n",
            "  Likelihood: High\n",
            "  Mitigation: Set 24–48h review window; identify delegate approvers; use async comments\n",
            "  Owner: Stakeholder Sponsor\n",
            "\n",
            "- Risk: Tooling or version-control issues\n",
            "  Impact: Low — rework\n",
            "  Likelihood: Medium\n",
            "  Mitigation: Single-source doc; change log; export to PDF before circu\n",
            "\n",
            "=== ACTUAL SPEND (approx) ===\n",
            "Spend(tokens=1819, latency_ms=56706, tool_calls=2)\n",
            "\n",
            "Within budget? False\n"
          ]
        }
      ],
      "source": [
        "def run_local_step(task: str, step: StepOption, working: Dict[str, Any]) -> str:\n",
        "    name = step.name.lower()\n",
        "    if \"clarify deliverables\" in name:\n",
        "        return (\n",
        "            \"Deliverables checklist:\\n\"\n",
        "            \"- Executive summary\\n- Scope & assumptions\\n- Workplan + milestones\\n\"\n",
        "            \"- Risk register (risk, impact, likelihood, mitigation, owner)\\n\"\n",
        "            \"- Next steps + data needed\\n\"\n",
        "        )\n",
        "    if \"outline plan\" in name:\n",
        "        return (\n",
        "            \"Outline:\\n1) Context & objective\\n2) Scope\\n3) Approach\\n4) Timeline\\n5) Risks\\n6) Next steps\\n\"\n",
        "        )\n",
        "    if \"risk register\" in name:\n",
        "        return (\n",
        "            \"Risk register (template):\\n\"\n",
        "            \"1) Data access delays | High | Mitigation: agree data list + owners\\n\"\n",
        "            \"2) Stakeholder alignment | Med | Mitigation: weekly review\\n\"\n",
        "            \"3) Tooling constraints | Med | Mitigation: phased rollout\\n\"\n",
        "        )\n",
        "    if \"timeline\" in name:\n",
        "        return (\n",
        "            \"Timeline (template):\\n\"\n",
        "            \"Week 1: discovery + requirements\\nWeek 2: prototype + feedback\\n\"\n",
        "            \"Week 3: pilot + metrics\\nWeek 4: rollout + handover\\n\"\n",
        "        )\n",
        "    if \"quality pass\" in name:\n",
        "        draft = working.get(\"draft\", \"\")\n",
        "        return \"Light quality pass done (headings normalized, bullets aligned).\\n\" + draft\n",
        "    return f\"Completed: {step.name}\\n\"\n",
        "\n",
        "def run_llm_step(task: str, step: StepOption, working: Dict[str, Any]) -> str:\n",
        "    kind = step.payload.get(\"prompt_kind\", \"generic\")\n",
        "    context = working.get(\"draft\", \"\")\n",
        "    prompts = {\n",
        "        \"outline\": f\"Create a crisp, structured outline for the task below.\\nTASK:\\n{task}\\nReturn a numbered outline.\",\n",
        "        \"risks\": f\"Create a risk register for the task below. Include: Risk | Impact | Likelihood | Mitigation | Owner.\\nTASK:\\n{task}\",\n",
        "        \"timeline\": f\"Create a realistic milestone timeline with dependencies for the task below.\\nTASK:\\n{task}\",\n",
        "        \"polish\": f\"Rewrite and polish the following draft for clarity and consistency.\\nDRAFT:\\n{context}\",\n",
        "        \"generic\": f\"Help with this step: {step.description}\\nTASK:\\n{task}\\nCURRENT:\\n{context}\",\n",
        "    }\n",
        "    return llm_text(prompts.get(kind, prompts[\"generic\"]), model=\"gpt-5\", effort=\"low\")\n",
        "\n",
        "def execute_plan(task: str, plan: PlanCandidate) -> Tuple[str, Spend]:\n",
        "    working = {\"draft\": \"\"}\n",
        "    actual = Spend()\n",
        "\n",
        "    for i, step in enumerate(plan.steps, 1):\n",
        "        t0 = time.time()\n",
        "        if step.executor == \"llm\" and USE_OPENAI:\n",
        "            out = run_llm_step(task, step, working)\n",
        "            tool_calls = 1\n",
        "        else:\n",
        "            out = run_local_step(task, step, working)\n",
        "            tool_calls = 0\n",
        "\n",
        "        dt_ms = int((time.time() - t0) * 1000)\n",
        "        tok = approx_tokens(out)\n",
        "\n",
        "        actual = actual.add(Spend(tokens=tok, latency_ms=dt_ms, tool_calls=tool_calls))\n",
        "        working[\"draft\"] += f\"\\n\\n### Step {i}: {step.name}\\n{out}\\n\"\n",
        "\n",
        "    return working[\"draft\"].strip(), actual\n",
        "\n",
        "TASK = \"Draft a 1-page project proposal for a logistics dashboard + fleet optimization pilot, including scope, timeline, and risks.\"\n",
        "BUDGET = Budget(\n",
        "    max_tokens=2200,\n",
        "    max_latency_ms=3500,\n",
        "    max_tool_calls=2\n",
        ")\n",
        "\n",
        "options = generate_step_options(TASK)\n",
        "best_plan = plan_under_budget(options, BUDGET, max_steps=6, beam_width=14)\n",
        "\n",
        "print(\"=== SELECTED PLAN (budget-aware) ===\")\n",
        "for s in best_plan.steps:\n",
        "    print(f\"- {s.name} | est_spend={s.est_spend} | est_value={s.est_value}\")\n",
        "print(\"\\nEstimated spend:\", best_plan.spend)\n",
        "print(\"Budget:\", BUDGET)\n",
        "\n",
        "print(\"\\n=== EXECUTING PLAN ===\")\n",
        "draft, actual = execute_plan(TASK, best_plan)\n",
        "\n",
        "print(\"\\n=== OUTPUT DRAFT ===\\n\")\n",
        "print(draft[:6000])\n",
        "\n",
        "print(\"\\n=== ACTUAL SPEND (approx) ===\")\n",
        "print(actual)\n",
        "print(\"\\nWithin budget?\", actual.within(BUDGET))"
      ]
    }
  ]
}