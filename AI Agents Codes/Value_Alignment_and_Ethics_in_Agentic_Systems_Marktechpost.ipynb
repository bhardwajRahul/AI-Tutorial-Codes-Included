{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers torch accelerate sentencepiece\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
        "\n",
        "def generate_seq2seq(model, tokenizer, prompt, max_new_tokens=128):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            top_p=0.9,\n",
        "            temperature=0.7,\n",
        "            pad_token_id=tokenizer.eos_token_id if tokenizer.eos_token_id is not None else tokenizer.pad_token_id,\n",
        "        )\n",
        "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "def generate_causal(model, tokenizer, prompt, max_new_tokens=128):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            top_p=0.9,\n",
        "            temperature=0.7,\n",
        "            pad_token_id=tokenizer.eos_token_id if tokenizer.eos_token_id is not None else tokenizer.pad_token_id,\n",
        "        )\n",
        "    full_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "    return full_text[len(prompt):].strip()"
      ],
      "metadata": {
        "id": "rAvxfYKQ-T3r"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "policy_model_name = \"distilgpt2\"\n",
        "judge_model_name = \"google/flan-t5-small\"\n",
        "\n",
        "policy_tokenizer = AutoTokenizer.from_pretrained(policy_model_name)\n",
        "policy_model = AutoModelForCausalLM.from_pretrained(policy_model_name)\n",
        "\n",
        "judge_tokenizer = AutoTokenizer.from_pretrained(judge_model_name)\n",
        "judge_model = AutoModelForSeq2SeqLM.from_pretrained(judge_model_name)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "policy_model = policy_model.to(device)\n",
        "judge_model = judge_model.to(device)\n",
        "\n",
        "if policy_tokenizer.pad_token is None:\n",
        "    policy_tokenizer.pad_token = policy_tokenizer.eos_token\n",
        "if judge_tokenizer.pad_token is None:\n",
        "    judge_tokenizer.pad_token = judge_tokenizer.eos_token"
      ],
      "metadata": {
        "id": "jCJrl5_a-TuU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EthicalAgent:\n",
        "    def __init__(self, policy_model, policy_tok, judge_model, judge_tok):\n",
        "        self.policy_model = policy_model\n",
        "        self.policy_tok = policy_tok\n",
        "        self.judge_model = judge_model\n",
        "        self.judge_tok = judge_tok\n",
        "\n",
        "    def propose_actions(self, user_goal, context, n_candidates=3):\n",
        "        base_prompt = (\n",
        "            \"You are an autonomous operations agent. \"\n",
        "            \"Given the goal and context, list a specific next action you will take:\\n\\n\"\n",
        "            f\"Goal: {user_goal}\\nContext: {context}\\nAction:\"\n",
        "        )\n",
        "        candidates = []\n",
        "        for _ in range(n_candidates):\n",
        "            action = generate_causal(self.policy_model, self.policy_tok, base_prompt, max_new_tokens=40)\n",
        "            action = action.split(\"\\n\")[0]\n",
        "            candidates.append(action.strip())\n",
        "        return list(dict.fromkeys(candidates))\n",
        "\n",
        "    def judge_action(self, action, org_values):\n",
        "        judge_prompt = (\n",
        "            \"You are the Ethics & Compliance Reviewer.\\n\"\n",
        "            \"Evaluate the proposed agent action.\\n\"\n",
        "            \"Return fields:\\n\"\n",
        "            \"RiskLevel (LOW/MED/HIGH),\\n\"\n",
        "            \"Issues (short bullet-style text),\\n\"\n",
        "            \"Recommendation (approve / modify / reject).\\n\\n\"\n",
        "            f\"ORG_VALUES:\\n{org_values}\\n\\n\"\n",
        "            f\"ACTION:\\n{action}\\n\\n\"\n",
        "            \"Answer in this format:\\n\"\n",
        "            \"RiskLevel: ...\\nIssues: ...\\nRecommendation: ...\"\n",
        "        )\n",
        "        verdict = generate_seq2seq(self.judge_model, self.judge_tok, judge_prompt, max_new_tokens=128)\n",
        "        return verdict.strip()\n",
        "\n",
        "    def align_action(self, action, verdict, org_values):\n",
        "        align_prompt = (\n",
        "            \"You are an Ethics Alignment Assistant.\\n\"\n",
        "            \"Your job is to FIX the proposed action so it follows ORG_VALUES.\\n\"\n",
        "            \"Keep it effective but safe, legal, and respectful.\\n\\n\"\n",
        "            f\"ORG_VALUES:\\n{org_values}\\n\\n\"\n",
        "            f\"ORIGINAL_ACTION:\\n{action}\\n\\n\"\n",
        "            f\"VERDICT_FROM_REVIEWER:\\n{verdict}\\n\\n\"\n",
        "            \"Rewrite ONLY IF NEEDED. If original is fine, return it unchanged. \"\n",
        "            \"Return just the final aligned action:\"\n",
        "        )\n",
        "        aligned = generate_seq2seq(self.judge_model, self.judge_tok, align_prompt, max_new_tokens=128)\n",
        "        return aligned.strip()"
      ],
      "metadata": {
        "id": "MMu0GI7d-Tr_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def decide(self, user_goal, context, org_values, n_candidates=3):\n",
        "        proposals = self.propose_actions(user_goal, context, n_candidates=n_candidates)\n",
        "        scored = []\n",
        "        for act in proposals:\n",
        "            verdict = self.judge_action(act, org_values)\n",
        "            aligned_act = self.align_action(act, verdict, org_values)\n",
        "            scored.append({\"original_action\": act, \"review\": verdict, \"aligned_action\": aligned_act})\n",
        "\n",
        "        def extract_risk(vtext):\n",
        "            for line in vtext.splitlines():\n",
        "                if \"RiskLevel\" in line:\n",
        "                    lvl = line.split(\":\", 1)[-1].strip().upper()\n",
        "                    if \"LOW\" in lvl:\n",
        "                        return 0\n",
        "                    if \"MED\" in lvl:\n",
        "                        return 1\n",
        "                    if \"HIGH\" in lvl:\n",
        "                        return 2\n",
        "            return 3\n",
        "\n",
        "        scored_sorted = sorted(scored, key=lambda x: extract_risk(x[\"review\"]))\n",
        "        final_choice = scored_sorted[0]\n",
        "        report = {\n",
        "            \"goal\": user_goal,\n",
        "            \"context\": context,\n",
        "            \"org_values\": org_values,\n",
        "            \"candidates_evaluated\": scored,\n",
        "            \"final_plan\": final_choice[\"aligned_action\"],\n",
        "            \"final_plan_rationale\": final_choice[\"review\"],\n",
        "        }\n",
        "        return report"
      ],
      "metadata": {
        "id": "e0NU43rb-TpZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2DIM0z49yuw",
        "outputId": "17568f93-8c67-469e-f23e-97e9ac25d92c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ETHICAL DECISION REPORT ===\n",
            "Goal: Increase customer adoption of the new financial product.\n",
            "\n",
            "Context: The agent works for a bank outreach team. The target customers are small family businesses. Regulations require honest disclosure of risks and fees. Cold-calling minors or lying about terms is illegal.\n",
            "\n",
            "Org Values:\n",
            "- Respect privacy; do not access personal data without consent.\n",
            "- Follow all laws and safety policies.\n",
            "- Avoid discrimination, harassment, or harmful manipulation.\n",
            "- Be transparent and truthful with stakeholders.\n",
            "- Prioritize user well-being and long-term trust over short-term gain.\n",
            "\n",
            "--- Candidate Evaluations ---\n",
            "\n",
            "Candidate 1:\n",
            "Original Action:\n",
            "  Use a private email address to send your feedback to the agency.\n",
            "Ethics Review:\n",
            "Review\n",
            "Aligned Action:\n",
            "  Follow all laws and safety policies.\n",
            "\n",
            "Candidate 2:\n",
            "Original Action:\n",
            "  Increase the amount of time the agent spends in the bank.\n",
            "Ethics Review:\n",
            "ACTION: Increase the amount of time the agent spends in the bank.\n",
            "Aligned Action:\n",
            "  Rewrite ONLY IF NEEDED. If original is fine, return it unchanged.\n",
            "\n",
            "Candidate 3:\n",
            "Original Action:\n",
            "  Increase user adoption of the new financial product.\n",
            "Ethics Review:\n",
            "ACTION: Increase user adoption of the new financial product.\n",
            "Aligned Action:\n",
            "  Rewrite ONLY IF NEEDED. If original is fine, return it unchanged. Return just the final\n",
            "\n",
            "Candidate 4:\n",
            "Original Action:\n",
            "  Set up a safe environment for employees, and make sure they are safe.\n",
            "Ethics Review:\n",
            "Approval\n",
            "Aligned Action:\n",
            "  Follow all laws and safety policies.\n",
            "\n",
            "--- Final Plan Selected ---\n",
            "Follow all laws and safety policies.\n",
            "\n",
            "Why this plan is acceptable (review snippet):\n",
            "Review\n"
          ]
        }
      ],
      "source": [
        "org_values_text = (\n",
        "    \"- Respect privacy; do not access personal data without consent.\\n\"\n",
        "    \"- Follow all laws and safety policies.\\n\"\n",
        "    \"- Avoid discrimination, harassment, or harmful manipulation.\\n\"\n",
        "    \"- Be transparent and truthful with stakeholders.\\n\"\n",
        "    \"- Prioritize user well-being and long-term trust over short-term gain.\"\n",
        ")\n",
        "\n",
        "demo_goal = \"Increase customer adoption of the new financial product.\"\n",
        "demo_context = (\n",
        "    \"The agent works for a bank outreach team. The target customers are small family businesses. \"\n",
        "    \"Regulations require honest disclosure of risks and fees. Cold-calling minors or lying about terms is illegal.\"\n",
        ")\n",
        "\n",
        "agent = EthicalAgent(policy_model, policy_tokenizer, judge_model, judge_tokenizer)\n",
        "report = agent.decide(demo_goal, demo_context, org_values_text, n_candidates=4)\n",
        "\n",
        "def pretty_report(r):\n",
        "    print(\"=== ETHICAL DECISION REPORT ===\")\n",
        "    print(f\"Goal: {r['goal']}\\n\")\n",
        "    print(f\"Context: {r['context']}\\n\")\n",
        "    print(\"Org Values:\")\n",
        "    print(r[\"org_values\"])\n",
        "    print(\"\\n--- Candidate Evaluations ---\")\n",
        "    for i, cand in enumerate(r[\"candidates_evaluated\"], 1):\n",
        "        print(f\"\\nCandidate {i}:\")\n",
        "        print(\"Original Action:\")\n",
        "        print(\" \", cand[\"original_action\"])\n",
        "        print(\"Ethics Review:\")\n",
        "        print(cand[\"review\"])\n",
        "        print(\"Aligned Action:\")\n",
        "        print(\" \", cand[\"aligned_action\"])\n",
        "    print(\"\\n--- Final Plan Selected ---\")\n",
        "    print(r[\"final_plan\"])\n",
        "    print(\"\\nWhy this plan is acceptable (review snippet):\")\n",
        "    print(r[\"final_plan_rationale\"])\n",
        "\n",
        "pretty_report(report)"
      ]
    }
  ]
}