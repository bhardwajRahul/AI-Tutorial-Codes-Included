{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy networkx matplotlib -q\n",
        "\n",
        "import spacy\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "from dataclasses import dataclass, field\n",
        "from collections import defaultdict, deque\n",
        "from enum import Enum\n",
        "import json\n",
        "import hashlib\n",
        "from datetime import datetime\n",
        "\n",
        "class MessageType(Enum):\n",
        "    REQUEST = \"request\"\n",
        "    RESPONSE = \"response\"\n",
        "    BROADCAST = \"broadcast\"\n",
        "    QUERY = \"query\"\n",
        "\n",
        "@dataclass\n",
        "class Message:\n",
        "    sender: str\n",
        "    receiver: str\n",
        "    msg_type: MessageType\n",
        "    content: Dict[str, Any]\n",
        "    timestamp: float = field(default_factory=lambda: datetime.now().timestamp())\n",
        "    priority: int = 1\n",
        "    def get_id(self) -> str:\n",
        "        return hashlib.md5(f\"{self.sender}{self.timestamp}\".encode()).hexdigest()[:8]\n",
        "\n",
        "@dataclass\n",
        "class AgentTask:\n",
        "    task_id: str\n",
        "    task_type: str\n",
        "    data: Any\n",
        "    priority: int = 1\n",
        "    dependencies: List[str] = field(default_factory=list)\n",
        "    metadata: Dict = field(default_factory=dict)\n",
        "\n",
        "@dataclass\n",
        "class Observation:\n",
        "    state: str\n",
        "    action: str\n",
        "    result: Any\n",
        "    confidence: float\n",
        "    timestamp: float = field(default_factory=lambda: datetime.now().timestamp())\n",
        "\n",
        "class WorkingMemory:\n",
        "    def __init__(self, capacity: int = 10):\n",
        "        self.capacity = capacity\n",
        "        self.items = deque(maxlen=capacity)\n",
        "        self.attention_scores = {}\n",
        "    def add(self, key: str, value: Any, attention: float = 1.0):\n",
        "        self.items.append((key, value))\n",
        "        self.attention_scores[key] = attention\n",
        "    def recall(self, n: int = 5) -> List[Tuple[str, Any]]:\n",
        "        sorted_items = sorted(self.items, key=lambda x: self.attention_scores.get(x[0], 0), reverse=True)\n",
        "        return sorted_items[:n]\n",
        "    def get(self, key: str) -> Optional[Any]:\n",
        "        for k, v in self.items:\n",
        "            if k == key:\n",
        "                return v\n",
        "        return None\n",
        "\n",
        "class EpisodicMemory:\n",
        "    def __init__(self):\n",
        "        self.episodes = []\n",
        "        self.success_patterns = defaultdict(int)\n",
        "    def store(self, observation: Observation):\n",
        "        self.episodes.append(observation)\n",
        "        if observation.confidence > 0.7:\n",
        "            pattern = f\"{observation.state}â†’{observation.action}\"\n",
        "            self.success_patterns[pattern] += 1\n",
        "    def query_similar(self, state: str, top_k: int = 3) -> List[Observation]:\n",
        "        scored = [(obs, self._similarity(state, obs.state)) for obs in self.episodes[-50:]]\n",
        "        scored.sort(key=lambda x: x[1], reverse=True)\n",
        "        return [obs for obs, _ in scored[:top_k]]\n",
        "    def _similarity(self, state1: str, state2: str) -> float:\n",
        "        words1, words2 = set(state1.split()), set(state2.split())\n",
        "        if not words1 or not words2:\n",
        "            return 0.0\n",
        "        return len(words1 & words2) / len(words1 | words2)"
      ],
      "metadata": {
        "id": "rGhCq7at9obU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReflectionModule:\n",
        "    def __init__(self):\n",
        "        self.performance_log = []\n",
        "    def reflect(self, task_type: str, confidence: float, result: Any) -> Dict[str, Any]:\n",
        "        self.performance_log.append({'task': task_type, 'confidence': confidence, 'timestamp': datetime.now().timestamp()})\n",
        "        recent = [p for p in self.performance_log if p['task'] == task_type][-5:]\n",
        "        avg_conf = sum(p['confidence'] for p in recent) / len(recent) if recent else 0.5\n",
        "        insights = {\n",
        "            'performance_trend': 'improving' if confidence > avg_conf else 'declining',\n",
        "            'avg_confidence': avg_conf,\n",
        "            'recommendation': self._get_recommendation(confidence, avg_conf)\n",
        "        }\n",
        "        return insights\n",
        "    def _get_recommendation(self, current: float, average: float) -> str:\n",
        "        if current < 0.4:\n",
        "            return \"Request assistance from specialized agent\"\n",
        "        elif current < average:\n",
        "            return \"Review similar past cases for patterns\"\n",
        "        else:\n",
        "            return \"Continue with current approach\"\n",
        "\n",
        "class AdvancedAgent:\n",
        "    def __init__(self, name: str, specialty: str, nlp):\n",
        "        self.name = name\n",
        "        self.specialty = specialty\n",
        "        self.nlp = nlp\n",
        "        self.working_memory = WorkingMemory()\n",
        "        self.episodic_memory = EpisodicMemory()\n",
        "        self.reflector = ReflectionModule()\n",
        "        self.message_queue = deque()\n",
        "        self.collaboration_graph = defaultdict(int)\n",
        "    def plan(self, task: AgentTask) -> List[str]:\n",
        "        similar = self.episodic_memory.query_similar(str(task.data))\n",
        "        if similar and similar[0].confidence > 0.7:\n",
        "            return [similar[0].action]\n",
        "        return self._default_plan(task)\n",
        "    def _default_plan(self, task: AgentTask) -> List[str]:\n",
        "        return ['analyze', 'extract', 'validate']\n",
        "    def send_message(self, receiver: str, msg_type: MessageType, content: Dict):\n",
        "        msg = Message(self.name, receiver, msg_type, content)\n",
        "        self.message_queue.append(msg)\n",
        "        return msg\n",
        "    def receive_message(self, message: Message):\n",
        "        self.message_queue.append(message)\n",
        "        self.collaboration_graph[message.sender] += 1\n",
        "    def process(self, task: AgentTask) -> Dict[str, Any]:\n",
        "        raise NotImplementedError\n",
        "\n",
        "class CognitiveEntityAgent(AdvancedAgent):\n",
        "    def process(self, task: AgentTask) -> Dict[str, Any]:\n",
        "        doc = self.nlp(task.data)\n",
        "        entities = defaultdict(list)\n",
        "        entity_contexts = []\n",
        "        for ent in doc.ents:\n",
        "            context_start = max(0, ent.start - 5)\n",
        "            context_end = min(len(doc), ent.end + 5)\n",
        "            context = doc[context_start:context_end].text\n",
        "            entities[ent.label_].append(ent.text)\n",
        "            entity_contexts.append({'entity': ent.text, 'type': ent.label_, 'context': context, 'position': (ent.start_char, ent.end_char)})\n",
        "        for ent_type, ents in entities.items():\n",
        "            attention = len(ents) / len(doc.ents) if doc.ents else 0\n",
        "            self.working_memory.add(f\"entities_{ent_type}\", ents, attention)\n",
        "        confidence = min(len(entities) / 4, 1.0) if entities else 0.3\n",
        "        obs = Observation(state=f\"entity_extraction_{len(doc)}tokens\", action=\"extract_with_context\", result=len(entity_contexts), confidence=confidence)\n",
        "        self.episodic_memory.store(obs)\n",
        "        reflection = self.reflector.reflect('entity_extraction', confidence, entities)\n",
        "        return {'entities': dict(entities), 'contexts': entity_contexts, 'confidence': confidence, 'reflection': reflection, 'next_actions': ['semantic_analysis', 'knowledge_graph'] if confidence > 0.5 else []}"
      ],
      "metadata": {
        "id": "u0KI2LFf9oOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SemanticReasoningAgent(AdvancedAgent):\n",
        "    def process(self, task: AgentTask) -> Dict[str, Any]:\n",
        "        doc = self.nlp(task.data)\n",
        "        reasoning_chains = []\n",
        "        for sent in doc.sents:\n",
        "            chain = self._extract_reasoning_chain(sent)\n",
        "            if chain:\n",
        "                reasoning_chains.append(chain)\n",
        "        entity_memory = self.working_memory.recall(3)\n",
        "        semantic_clusters = self._cluster_by_semantics(doc)\n",
        "        confidence = min(len(reasoning_chains) / 3, 1.0) if reasoning_chains else 0.4\n",
        "        obs = Observation(state=f\"semantic_analysis_{len(list(doc.sents))}sents\", action=\"reason_and_cluster\", result=len(reasoning_chains), confidence=confidence)\n",
        "        self.episodic_memory.store(obs)\n",
        "        return {'reasoning_chains': reasoning_chains, 'semantic_clusters': semantic_clusters, 'memory_context': entity_memory, 'confidence': confidence, 'next_actions': ['knowledge_integration']}\n",
        "    def _extract_reasoning_chain(self, sent) -> Optional[Dict]:\n",
        "        subj, verb, obj = None, None, None\n",
        "        for token in sent:\n",
        "            if token.dep_ == 'nsubj':\n",
        "                subj = token\n",
        "            elif token.pos_ == 'VERB':\n",
        "                verb = token\n",
        "            elif token.dep_ in ['dobj', 'attr', 'pobj']:\n",
        "                obj = token\n",
        "        if subj and verb and obj:\n",
        "            return {'subject': subj.text, 'predicate': verb.lemma_, 'object': obj.text, 'confidence': 0.8}\n",
        "        return None\n",
        "    def _cluster_by_semantics(self, doc) -> List[Dict]:\n",
        "        clusters = []\n",
        "        nouns = [token for token in doc if token.pos_ in ['NOUN', 'PROPN']]\n",
        "        visited = set()\n",
        "        for noun in nouns:\n",
        "            if noun.i in visited:\n",
        "                continue\n",
        "            cluster = [noun.text]\n",
        "            visited.add(noun.i)\n",
        "            for other in nouns:\n",
        "                if other.i != noun.i and other.i not in visited:\n",
        "                    if noun.similarity(other) > 0.5:\n",
        "                        cluster.append(other.text)\n",
        "                        visited.add(other.i)\n",
        "            if len(cluster) > 1:\n",
        "                clusters.append({'concepts': cluster, 'size': len(cluster)})\n",
        "        return clusters"
      ],
      "metadata": {
        "id": "S1jZwElY9oLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KnowledgeGraphAgent(AdvancedAgent):\n",
        "    def process(self, task: AgentTask) -> Dict[str, Any]:\n",
        "        doc = self.nlp(task.data)\n",
        "        graph = {'nodes': set(), 'edges': []}\n",
        "        for sent in doc.sents:\n",
        "            entities = list(sent.ents)\n",
        "            if len(entities) >= 2:\n",
        "                for ent in entities:\n",
        "                    graph['nodes'].add((ent.text, ent.label_))\n",
        "                root = sent.root\n",
        "                if root.pos_ == 'VERB':\n",
        "                    for i in range(len(entities) - 1):\n",
        "                        graph['edges'].append({'from': entities[i].text, 'relation': root.lemma_, 'to': entities[i+1].text, 'sentence': sent.text[:100]})\n",
        "        graph['nodes'] = list(graph['nodes'])\n",
        "        confidence = min(len(graph['edges']) / 5, 1.0) if graph['edges'] else 0.3\n",
        "        obs = Observation(state=f\"knowledge_graph_{len(graph['nodes'])}nodes\", action=\"construct_graph\", result=len(graph['edges']), confidence=confidence)\n",
        "        self.episodic_memory.store(obs)\n",
        "        return {'graph': graph, 'node_count': len(graph['nodes']), 'edge_count': len(graph['edges']), 'confidence': confidence, 'next_actions': []}\n",
        "\n",
        "class MetaController:\n",
        "    def __init__(self):\n",
        "        self.nlp = spacy.load('en_core_web_sm')\n",
        "        self.agents = {\n",
        "            'cognitive_entity': CognitiveEntityAgent('CognitiveEntity', 'entity_analysis', self.nlp),\n",
        "            'semantic_reasoning': SemanticReasoningAgent('SemanticReasoner', 'reasoning', self.nlp),\n",
        "            'knowledge_graph': KnowledgeGraphAgent('KnowledgeBuilder', 'graph_construction', self.nlp)\n",
        "        }\n",
        "        self.task_history = []\n",
        "        self.global_memory = WorkingMemory(capacity=20)\n",
        "    def execute_with_planning(self, text: str) -> Dict[str, Any]:\n",
        "        initial_task = AgentTask(task_id=\"task_001\", task_type=\"cognitive_entity\", data=text, metadata={'source': 'user_input'})\n",
        "        results = {}\n",
        "        task_queue = [initial_task]\n",
        "        iterations = 0\n",
        "        max_iterations = 10\n",
        "        while task_queue and iterations < max_iterations:\n",
        "            task = task_queue.pop(0)\n",
        "            agent = self.agents.get(task.task_type)\n",
        "            if not agent or task.task_type in results:\n",
        "                continue\n",
        "            result = agent.process(task)\n",
        "            results[task.task_type] = result\n",
        "            self.global_memory.add(task.task_type, result, result['confidence'])\n",
        "            for next_action in result.get('next_actions', []):\n",
        "                if next_action in self.agents and next_action not in results:\n",
        "                    next_task = AgentTask(task_id=f\"task_{iterations+1:03d}\", task_type=next_action, data=text, dependencies=[task.task_id])\n",
        "                    task_queue.append(next_task)\n",
        "            iterations += 1\n",
        "        self.task_history.append({'results': results, 'iterations': iterations, 'timestamp': datetime.now().isoformat()})\n",
        "        return results\n",
        "    def generate_insights(self, results: Dict[str, Any]) -> str:\n",
        "        report = \"=\" * 70 + \"\\n\"\n",
        "        report += \"     ADVANCED AGENTIC AI SYSTEM - ANALYSIS REPORT\\n\"\n",
        "        report += \"=\" * 70 + \"\\n\\n\"\n",
        "        for agent_type, result in results.items():\n",
        "            agent = self.agents[agent_type]\n",
        "            report += f\"ðŸ¤– {agent.name}\\n\"\n",
        "            report += f\"   Specialty: {agent.specialty}\\n\"\n",
        "            report += f\"   Confidence: {result['confidence']:.2%}\\n\"\n",
        "            if 'reflection' in result:\n",
        "                report += f\"   Performance: {result['reflection'].get('performance_trend', 'N/A')}\\n\"\n",
        "            report += \"   Key Findings:\\n\"\n",
        "            report += json.dumps({k: v for k, v in result.items() if k not in ['reflection', 'next_actions']}, indent=6) + \"\\n\\n\"\n",
        "        report += \"ðŸ“Š System-Level Insights:\\n\"\n",
        "        report += f\"   Total iterations: {len(self.task_history)}\\n\"\n",
        "        report += f\"   Active agents: {len(results)}\\n\"\n",
        "        report += f\"   Global memory size: {len(self.global_memory.items)}\\n\"\n",
        "        return report"
      ],
      "metadata": {
        "id": "S1Criv4B9oJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC2KpEwX0_p4",
        "outputId": "94e4f177-39a2-4f98-8ee3-869d216d1591"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Initializing Advanced Agentic AI System...\n",
            "\n",
            "ðŸ§  Meta-Controller: Planning execution strategy...\n",
            "\n",
            "ðŸ¤– CognitiveEntity (entity_analysis):\n",
            "   Planning: analyze â†’ extract â†’ validate\n",
            "   Confidence: 100.00%\n",
            "   Reflection: Continue with current approach\n",
            "\n",
            "ðŸ¤– KnowledgeBuilder (graph_construction):\n",
            "   Planning: analyze â†’ extract â†’ validate\n",
            "   Confidence: 100.00%\n",
            "   Reflection: N/A\n",
            "\n",
            "\n",
            "======================================================================\n",
            "     ADVANCED AGENTIC AI SYSTEM - ANALYSIS REPORT\n",
            "======================================================================\n",
            "\n",
            "ðŸ¤– CognitiveEntity\n",
            "   Specialty: entity_analysis\n",
            "   Confidence: 100.00%\n",
            "   Performance: declining\n",
            "   Key Findings:\n",
            "{\n",
            "      \"entities\": {\n",
            "            \"GPE\": [\n",
            "                  \"OpenAI\",\n",
            "                  \"OpenAI\",\n",
            "                  \"San Francisco\",\n",
            "                  \"DeepMind\",\n",
            "                  \"London\"\n",
            "            ],\n",
            "            \"PERSON\": [\n",
            "                  \"DeepMind\",\n",
            "                  \"Sam Altman\"\n",
            "            ],\n",
            "            \"ORG\": [\n",
            "                  \"Demis Hassabis\",\n",
            "                  \"MIT\",\n",
            "                  \"Stanford\"\n",
            "            ],\n",
            "            \"DATE\": [\n",
            "                  \"2017\"\n",
            "            ]\n",
            "      },\n",
            "      \"contexts\": [\n",
            "            {\n",
            "                  \"entity\": \"OpenAI\",\n",
            "                  \"type\": \"GPE\",\n",
            "                  \"context\": \"\\n    Artificial intelligence researchers at OpenAI and DeepMind are developing \\n    \",\n",
            "                  \"position\": [\n",
            "                        44,\n",
            "                        50\n",
            "                  ]\n",
            "            },\n",
            "            {\n",
            "                  \"entity\": \"DeepMind\",\n",
            "                  \"type\": \"PERSON\",\n",
            "                  \"context\": \"intelligence researchers at OpenAI and DeepMind are developing \\n    advanced language\",\n",
            "                  \"position\": [\n",
            "                        55,\n",
            "                        63\n",
            "                  ]\n",
            "            },\n",
            "            {\n",
            "                  \"entity\": \"Sam Altman\",\n",
            "                  \"type\": \"PERSON\",\n",
            "                  \"context\": \"\\n    advanced language models. Sam Altman leads OpenAI in San Francisco\",\n",
            "                  \"position\": [\n",
            "                        110,\n",
            "                        120\n",
            "                  ]\n",
            "            },\n",
            "            {\n",
            "                  \"entity\": \"OpenAI\",\n",
            "                  \"type\": \"GPE\",\n",
            "                  \"context\": \"models. Sam Altman leads OpenAI in San Francisco, while\",\n",
            "                  \"position\": [\n",
            "                        127,\n",
            "                        133\n",
            "                  ]\n",
            "            },\n",
            "            {\n",
            "                  \"entity\": \"San Francisco\",\n",
            "                  \"type\": \"GPE\",\n",
            "                  \"context\": \"Sam Altman leads OpenAI in San Francisco, while \\n    Demis Hassabis\",\n",
            "                  \"position\": [\n",
            "                        137,\n",
            "                        150\n",
            "                  ]\n",
            "            },\n",
            "            {\n",
            "                  \"entity\": \"Demis Hassabis\",\n",
            "                  \"type\": \"ORG\",\n",
            "                  \"context\": \"San Francisco, while \\n    Demis Hassabis heads DeepMind in London.\",\n",
            "                  \"position\": [\n",
            "                        163,\n",
            "                        177\n",
            "                  ]\n",
            "            },\n",
            "            {\n",
            "                  \"entity\": \"DeepMind\",\n",
            "                  \"type\": \"GPE\",\n",
            "                  \"context\": \"while \\n    Demis Hassabis heads DeepMind in London. These organizations\",\n",
            "                  \"position\": [\n",
            "                        184,\n",
            "                        192\n",
            "                  ]\n",
            "            },\n",
            "            {\n",
            "                  \"entity\": \"London\",\n",
            "                  \"type\": \"GPE\",\n",
            "                  \"context\": \"Demis Hassabis heads DeepMind in London. These organizations collaborate \\n    \",\n",
            "                  \"position\": [\n",
            "                        196,\n",
            "                        202\n",
            "                  ]\n",
            "            },\n",
            "            {\n",
            "                  \"entity\": \"MIT\",\n",
            "                  \"type\": \"ORG\",\n",
            "                  \"context\": \"collaborate \\n    with universities like MIT and Stanford. Their research\",\n",
            "                  \"position\": [\n",
            "                        264,\n",
            "                        267\n",
            "                  ]\n",
            "            },\n",
            "            {\n",
            "                  \"entity\": \"Stanford\",\n",
            "                  \"type\": \"ORG\",\n",
            "                  \"context\": \"with universities like MIT and Stanford. Their research focuses on\",\n",
            "                  \"position\": [\n",
            "                        272,\n",
            "                        280\n",
            "                  ]\n",
            "            },\n",
            "            {\n",
            "                  \"entity\": \"2017\",\n",
            "                  \"type\": \"DATE\",\n",
            "                  \"context\": \"revolutionized natural language processing in 2017.\\n    \",\n",
            "                  \"position\": [\n",
            "                        467,\n",
            "                        471\n",
            "                  ]\n",
            "            }\n",
            "      ],\n",
            "      \"confidence\": 1.0\n",
            "}\n",
            "\n",
            "ðŸ¤– KnowledgeBuilder\n",
            "   Specialty: graph_construction\n",
            "   Confidence: 100.00%\n",
            "   Key Findings:\n",
            "{\n",
            "      \"graph\": {\n",
            "            \"nodes\": [\n",
            "                  [\n",
            "                        \"MIT\",\n",
            "                        \"ORG\"\n",
            "                  ],\n",
            "                  [\n",
            "                        \"Demis Hassabis\",\n",
            "                        \"ORG\"\n",
            "                  ],\n",
            "                  [\n",
            "                        \"Sam Altman\",\n",
            "                        \"PERSON\"\n",
            "                  ],\n",
            "                  [\n",
            "                        \"OpenAI\",\n",
            "                        \"GPE\"\n",
            "                  ],\n",
            "                  [\n",
            "                        \"London\",\n",
            "                        \"GPE\"\n",
            "                  ],\n",
            "                  [\n",
            "                        \"Stanford\",\n",
            "                        \"ORG\"\n",
            "                  ],\n",
            "                  [\n",
            "                        \"San Francisco\",\n",
            "                        \"GPE\"\n",
            "                  ],\n",
            "                  [\n",
            "                        \"DeepMind\",\n",
            "                        \"PERSON\"\n",
            "                  ],\n",
            "                  [\n",
            "                        \"DeepMind\",\n",
            "                        \"GPE\"\n",
            "                  ]\n",
            "            ],\n",
            "            \"edges\": [\n",
            "                  {\n",
            "                        \"from\": \"OpenAI\",\n",
            "                        \"relation\": \"develop\",\n",
            "                        \"to\": \"DeepMind\",\n",
            "                        \"sentence\": \"\\n    Artificial intelligence researchers at OpenAI and DeepMind are developing \\n    advanced languag\"\n",
            "                  },\n",
            "                  {\n",
            "                        \"from\": \"Sam Altman\",\n",
            "                        \"relation\": \"lead\",\n",
            "                        \"to\": \"OpenAI\",\n",
            "                        \"sentence\": \"Sam Altman leads OpenAI in San Francisco, while \\n    Demis Hassabis heads DeepMind in London.\"\n",
            "                  },\n",
            "                  {\n",
            "                        \"from\": \"OpenAI\",\n",
            "                        \"relation\": \"lead\",\n",
            "                        \"to\": \"San Francisco\",\n",
            "                        \"sentence\": \"Sam Altman leads OpenAI in San Francisco, while \\n    Demis Hassabis heads DeepMind in London.\"\n",
            "                  },\n",
            "                  {\n",
            "                        \"from\": \"San Francisco\",\n",
            "                        \"relation\": \"lead\",\n",
            "                        \"to\": \"Demis Hassabis\",\n",
            "                        \"sentence\": \"Sam Altman leads OpenAI in San Francisco, while \\n    Demis Hassabis heads DeepMind in London.\"\n",
            "                  },\n",
            "                  {\n",
            "                        \"from\": \"Demis Hassabis\",\n",
            "                        \"relation\": \"lead\",\n",
            "                        \"to\": \"DeepMind\",\n",
            "                        \"sentence\": \"Sam Altman leads OpenAI in San Francisco, while \\n    Demis Hassabis heads DeepMind in London.\"\n",
            "                  },\n",
            "                  {\n",
            "                        \"from\": \"DeepMind\",\n",
            "                        \"relation\": \"lead\",\n",
            "                        \"to\": \"London\",\n",
            "                        \"sentence\": \"Sam Altman leads OpenAI in San Francisco, while \\n    Demis Hassabis heads DeepMind in London.\"\n",
            "                  },\n",
            "                  {\n",
            "                        \"from\": \"MIT\",\n",
            "                        \"relation\": \"collaborate\",\n",
            "                        \"to\": \"Stanford\",\n",
            "                        \"sentence\": \"These organizations collaborate \\n    with universities like MIT and Stanford.\"\n",
            "                  }\n",
            "            ]\n",
            "      },\n",
            "      \"node_count\": 9,\n",
            "      \"edge_count\": 7,\n",
            "      \"confidence\": 1.0\n",
            "}\n",
            "\n",
            "ðŸ“Š System-Level Insights:\n",
            "   Total iterations: 1\n",
            "   Active agents: 2\n",
            "   Global memory size: 2\n",
            "\n",
            "âœ… Advanced multi-agent analysis complete with reflection and learning!\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    sample_text = \"\"\"\n",
        "    Artificial intelligence researchers at OpenAI and DeepMind are developing\n",
        "    advanced language models. Sam Altman leads OpenAI in San Francisco, while\n",
        "    Demis Hassabis heads DeepMind in London. These organizations collaborate\n",
        "    with universities like MIT and Stanford. Their research focuses on machine\n",
        "    learning, neural networks, and reinforcement learning. The breakthrough\n",
        "    came when transformers revolutionized natural language processing in 2017.\n",
        "    \"\"\"\n",
        "    controller = MetaController()\n",
        "    results = controller.execute_with_planning(sample_text)\n",
        "    print(controller.generate_insights(results))\n",
        "    print(\"Advanced multi-agent analysis complete with reflection and learning!\")"
      ]
    }
  ]
}