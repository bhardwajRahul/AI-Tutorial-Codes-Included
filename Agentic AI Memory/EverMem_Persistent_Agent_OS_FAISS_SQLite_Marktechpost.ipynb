{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "db2d831db42f4a1095af8529509e797e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_447480f32e134c59aad2982332914df8",
              "IPY_MODEL_e506ecea9e304da7917e8632651a9109",
              "IPY_MODEL_7b4e454a13f442b3b5b256b802ede7f7"
            ],
            "layout": "IPY_MODEL_6bc914c995f141f285575457ae8470a1"
          }
        },
        "447480f32e134c59aad2982332914df8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_522a59e492de4c7fafb3748bb8057d37",
            "placeholder": "​",
            "style": "IPY_MODEL_d67486a04d1b426eab076b027df9a2fd",
            "value": "Loading weights: 100%"
          }
        },
        "e506ecea9e304da7917e8632651a9109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a18f5f1ed225471bb207585ba08e8dd0",
            "max": 103,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9ac77293b9b44ecbda4692a6ea0d91a",
            "value": 103
          }
        },
        "7b4e454a13f442b3b5b256b802ede7f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_caf8e0d810ae4759a3c248d087563f8b",
            "placeholder": "​",
            "style": "IPY_MODEL_d031516a6fa947818ced7eb3add92328",
            "value": " 103/103 [00:00&lt;00:00, 336.44it/s, Materializing param=pooler.dense.weight]"
          }
        },
        "6bc914c995f141f285575457ae8470a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "522a59e492de4c7fafb3748bb8057d37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d67486a04d1b426eab076b027df9a2fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a18f5f1ed225471bb207585ba08e8dd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9ac77293b9b44ecbda4692a6ea0d91a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "caf8e0d810ae4759a3c248d087563f8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d031516a6fa947818ced7eb3add92328": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07b6a4d101da40d0ae34901f6d5ab51f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b67475766d94c2a8d96bfbe4fb50410",
              "IPY_MODEL_9da7897f19204f168776f0f8245019c7",
              "IPY_MODEL_58be584b67384fbe8d809be43f8ac7c7"
            ],
            "layout": "IPY_MODEL_42879b69ef194448a5ddd1f865612383"
          }
        },
        "6b67475766d94c2a8d96bfbe4fb50410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42e8ae2a44804734bb62b76688148f9b",
            "placeholder": "​",
            "style": "IPY_MODEL_e144c36b294748e4ad79af54ff43d444",
            "value": "Loading weights: 100%"
          }
        },
        "9da7897f19204f168776f0f8245019c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae51cc5faa4046f3bf04cef1b7abdbba",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3af6adf8891c4ce4878f2a74bdb71b09",
            "value": 190
          }
        },
        "58be584b67384fbe8d809be43f8ac7c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3955ecec59ea415c83fa0f5b11e41edc",
            "placeholder": "​",
            "style": "IPY_MODEL_633cb1bbd0384a5687b61a5f592af84b",
            "value": " 190/190 [00:00&lt;00:00, 365.71it/s, Materializing param=shared.weight]"
          }
        },
        "42879b69ef194448a5ddd1f865612383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42e8ae2a44804734bb62b76688148f9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e144c36b294748e4ad79af54ff43d444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae51cc5faa4046f3bf04cef1b7abdbba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3af6adf8891c4ce4878f2a74bdb71b09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3955ecec59ea415c83fa0f5b11e41edc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "633cb1bbd0384a5687b61a5f592af84b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U transformers sentence-transformers faiss-cpu accelerate\n",
        "\n",
        "import os, time, json, math, sqlite3, hashlib\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Any, Optional\n",
        "import numpy as np\n",
        "import faiss\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "def _now_ts():\n",
        "    return int(time.time())\n",
        "\n",
        "def _sha(s: str) -> str:\n",
        "    return hashlib.sha256(s.encode(\"utf-8\", errors=\"ignore\")).hexdigest()[:16]\n",
        "\n",
        "def _ensure_dir(p: str):\n",
        "    os.makedirs(p, exist_ok=True)\n",
        "\n",
        "def _safe_clip(text: str, max_chars: int = 1800) -> str:\n",
        "    text = (text or \"\").strip()\n",
        "    if len(text) <= max_chars:\n",
        "        return text\n",
        "    return text[:max_chars].rstrip() + \" …\"\n",
        "\n",
        "@dataclass\n",
        "class MemoryItem:\n",
        "    mid: str\n",
        "    role: str\n",
        "    text: str\n",
        "    created_ts: int\n",
        "    importance: float\n",
        "    tokens_est: int\n",
        "    meta: Dict[str, Any]"
      ],
      "metadata": {
        "id": "gIHjojsXZjnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EverMemAgentOS:\n",
        "    def __init__(\n",
        "        self,\n",
        "        workdir: str = \"/content/evermem_agent_os\",\n",
        "        db_name: str = \"evermem.sqlite\",\n",
        "        embedding_model: str = \"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "        gen_model: str = \"google/flan-t5-small\",\n",
        "        stm_max_turns: int = 10,\n",
        "        ltm_topk: int = 6,\n",
        "        consolidate_every: int = 8,\n",
        "        consolidate_trigger_tokens: int = 1400,\n",
        "        compress_target_chars: int = 420,\n",
        "        seed: int = 7,\n",
        "    ):\n",
        "        self.workdir = workdir\n",
        "        _ensure_dir(self.workdir)\n",
        "        self.db_path = os.path.join(self.workdir, db_name)\n",
        "\n",
        "        self.embedder = SentenceTransformer(embedding_model)\n",
        "        self.embed_dim = self.embedder.get_sentence_embedding_dimension()\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(gen_model)\n",
        "        self.model = AutoModelForSeq2SeqLM.from_pretrained(gen_model)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "\n",
        "        self.stm_max_turns = stm_max_turns\n",
        "        self.ltm_topk = ltm_topk\n",
        "        self.consolidate_every = consolidate_every\n",
        "        self.consolidate_trigger_tokens = consolidate_trigger_tokens\n",
        "        self.compress_target_chars = compress_target_chars\n",
        "\n",
        "        np.random.seed(seed)\n",
        "\n",
        "        self._init_db()\n",
        "        self._init_faiss()\n",
        "\n",
        "        self.stm: List[Dict[str, str]] = []\n",
        "        self.turns = 0\n",
        "\n",
        "    def _init_db(self):\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cur = conn.cursor()\n",
        "        cur.execute(\n",
        "            \"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS memories (\n",
        "                mid TEXT PRIMARY KEY,\n",
        "                role TEXT,\n",
        "                text TEXT,\n",
        "                created_ts INTEGER,\n",
        "                importance REAL,\n",
        "                tokens_est INTEGER,\n",
        "                meta_json TEXT\n",
        "            )\n",
        "            \"\"\"\n",
        "        )\n",
        "        cur.execute(\n",
        "            \"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS kv_store (\n",
        "                k TEXT PRIMARY KEY,\n",
        "                v_json TEXT,\n",
        "                updated_ts INTEGER\n",
        "            )\n",
        "            \"\"\"\n",
        "        )\n",
        "        cur.execute(\n",
        "            \"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS consolidations (\n",
        "                cid TEXT PRIMARY KEY,\n",
        "                created_ts INTEGER,\n",
        "                summary TEXT,\n",
        "                source_mids_json TEXT\n",
        "            )\n",
        "            \"\"\"\n",
        "        )\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "    def _init_faiss(self):\n",
        "        self.faiss_index_path = os.path.join(self.workdir, \"faiss.index\")\n",
        "        self.faiss_map_path = os.path.join(self.workdir, \"faiss_map.json\")\n",
        "\n",
        "        if os.path.exists(self.faiss_index_path) and os.path.exists(self.faiss_map_path):\n",
        "            self.index = faiss.read_index(self.faiss_index_path)\n",
        "            with open(self.faiss_map_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                self.id_map = json.load(f)\n",
        "            self.id_map = {int(k): v for k, v in self.id_map.items()}\n",
        "            self.next_faiss_id = (max(self.id_map.keys()) + 1) if self.id_map else 0\n",
        "            return\n",
        "\n",
        "        self.index = faiss.IndexFlatIP(self.embed_dim)\n",
        "        self.id_map: Dict[int, str] = {}\n",
        "        self.next_faiss_id = 0\n",
        "        self._persist_faiss()\n",
        "\n",
        "    def _persist_faiss(self):\n",
        "        faiss.write_index(self.index, self.faiss_index_path)\n",
        "        with open(self.faiss_map_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump({str(k): v for k, v in self.id_map.items()}, f)\n",
        "\n",
        "    def _embed(self, texts: List[str]) -> np.ndarray:\n",
        "        vecs = self.embedder.encode(texts, convert_to_numpy=True, normalize_embeddings=True)\n",
        "        if vecs.ndim == 1:\n",
        "            vecs = vecs.reshape(1, -1)\n",
        "        return vecs.astype(\"float32\")\n",
        "\n",
        "    def _tokens_est(self, text: str) -> int:\n",
        "        text = text or \"\"\n",
        "        return max(1, int(len(text.split()) * 1.25))\n",
        "\n",
        "    def _importance_score(self, role: str, text: str, meta: Dict[str, Any]) -> float:\n",
        "        base = 0.35\n",
        "        length_bonus = min(0.45, math.log1p(len(text)) / 20.0)\n",
        "        role_bonus = 0.08 if role == \"user\" else 0.03\n",
        "        pin = 0.35 if meta.get(\"pinned\") else 0.0\n",
        "        signal = meta.get(\"signal\", \"\")\n",
        "        signal_bonus = 0.18 if signal in {\"decision\", \"preference\", \"fact\", \"task\"} else 0.0\n",
        "        q_bonus = 0.06 if \"?\" in text else 0.0\n",
        "        number_bonus = 0.05 if any(ch.isdigit() for ch in text) else 0.0\n",
        "        return float(min(1.0, base + length_bonus + role_bonus + pin + signal_bonus + q_bonus + number_bonus))\n",
        "\n",
        "    def upsert_kv(self, k: str, v: Any):\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cur = conn.cursor()\n",
        "        cur.execute(\n",
        "            \"INSERT INTO kv_store (k, v_json, updated_ts) VALUES (?, ?, ?) ON CONFLICT(k) DO UPDATE SET v_json=excluded.v_json, updated_ts=excluded.updated_ts\",\n",
        "            (k, json.dumps(v, ensure_ascii=False), _now_ts()),\n",
        "        )\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "    def get_kv(self, k: str, default=None):\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cur = conn.cursor()\n",
        "        cur.execute(\"SELECT v_json FROM kv_store WHERE k=?\", (k,))\n",
        "        row = cur.fetchone()\n",
        "        conn.close()\n",
        "        if not row:\n",
        "            return default\n",
        "        try:\n",
        "            return json.loads(row[0])\n",
        "        except Exception:\n",
        "            return default\n",
        "\n",
        "    def add_memory(self, role: str, text: str, meta: Optional[Dict[str, Any]] = None) -> str:\n",
        "        meta = meta or {}\n",
        "        text = (text or \"\").strip()\n",
        "        mid = meta.get(\"mid\") or f\"m:{_sha(f'{_now_ts()}::{role}::{text[:80]}::{np.random.randint(0, 10**9)}')}\"\n",
        "        created_ts = _now_ts()\n",
        "        tokens_est = self._tokens_est(text)\n",
        "        importance = float(meta.get(\"importance\")) if meta.get(\"importance\") is not None else self._importance_score(role, text, meta)\n",
        "\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cur = conn.cursor()\n",
        "        cur.execute(\n",
        "            \"INSERT OR REPLACE INTO memories (mid, role, text, created_ts, importance, tokens_est, meta_json) VALUES (?, ?, ?, ?, ?, ?, ?)\",\n",
        "            (mid, role, text, created_ts, importance, tokens_est, json.dumps(meta, ensure_ascii=False)),\n",
        "        )\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "        vec = self._embed([text])\n",
        "        fid = self.next_faiss_id\n",
        "        self.next_faiss_id += 1\n",
        "        self.index.add(vec)\n",
        "        self.id_map[fid] = mid\n",
        "        self._persist_faiss()\n",
        "\n",
        "        return mid"
      ],
      "metadata": {
        "id": "UXisaSNbZjmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def _fetch_memories_by_ids(self, mids: List[str]) -> List[MemoryItem]:\n",
        "        if not mids:\n",
        "            return []\n",
        "        placeholders = \",\".join([\"?\"] * len(mids))\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cur = conn.cursor()\n",
        "        cur.execute(\n",
        "            f\"SELECT mid, role, text, created_ts, importance, tokens_est, meta_json FROM memories WHERE mid IN ({placeholders})\",\n",
        "            mids,\n",
        "        )\n",
        "        rows = cur.fetchall()\n",
        "        conn.close()\n",
        "\n",
        "        items = []\n",
        "        for r in rows:\n",
        "            meta = {}\n",
        "            try:\n",
        "                meta = json.loads(r[6]) if r[6] else {}\n",
        "            except Exception:\n",
        "                meta = {}\n",
        "            items.append(\n",
        "                MemoryItem(\n",
        "                    mid=r[0],\n",
        "                    role=r[1],\n",
        "                    text=r[2],\n",
        "                    created_ts=int(r[3]),\n",
        "                    importance=float(r[4]),\n",
        "                    tokens_est=int(r[5]),\n",
        "                    meta=meta,\n",
        "                )\n",
        "            )\n",
        "        mid_pos = {m: i for i, m in enumerate(mids)}\n",
        "        items.sort(key=lambda x: mid_pos.get(x.mid, 10**9))\n",
        "        return items\n",
        "\n",
        "    def retrieve_ltm(self, query: str, topk: Optional[int] = None) -> List[MemoryItem]:\n",
        "        topk = topk or self.ltm_topk\n",
        "        qv = self._embed([query])\n",
        "        scores, ids = self.index.search(qv, topk + 8)\n",
        "        mids = []\n",
        "        for fid in ids[0].tolist():\n",
        "            if fid == -1:\n",
        "                continue\n",
        "            mid = self.id_map.get(int(fid))\n",
        "            if mid:\n",
        "                mids.append(mid)\n",
        "        mids = list(dict.fromkeys(mids))[:topk]\n",
        "        return self._fetch_memories_by_ids(mids)\n",
        "\n",
        "    def _format_stm(self) -> str:\n",
        "        turns = self.stm[-self.stm_max_turns:]\n",
        "        chunks = []\n",
        "        for t in turns:\n",
        "            chunks.append(f\"{t['role'].upper()}: {t['content']}\")\n",
        "        return \"\\n\".join(chunks).strip()\n",
        "\n",
        "    def _format_ltm(self, ltm_items: List[MemoryItem]) -> str:\n",
        "        if not ltm_items:\n",
        "            return \"\"\n",
        "        lines = []\n",
        "        for i, it in enumerate(ltm_items, 1):\n",
        "            ts_age = max(1, (_now_ts() - it.created_ts) // 3600)\n",
        "            imp = f\"{it.importance:.2f}\"\n",
        "            tag = it.meta.get(\"signal\", \"\")\n",
        "            tag = f\" | {tag}\" if tag else \"\"\n",
        "            lines.append(f\"[LTM {i}] (imp={imp}, age_h={ts_age}{tag}) {it.role}: {_safe_clip(it.text, 420)}\")\n",
        "        return \"\\n\".join(lines).strip()\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def _gen(self, prompt: str, max_new_tokens: int = 180) -> str:\n",
        "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(self.device)\n",
        "        out_ids = self.model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            temperature=0.6,\n",
        "            top_p=0.92,\n",
        "            num_beams=1,\n",
        "        )\n",
        "        out = self.tokenizer.decode(out_ids[0], skip_special_tokens=True)\n",
        "        return (out or \"\").strip()\n",
        "\n",
        "    def _compress_memories(self, items: List[MemoryItem], max_chars: int = 520) -> str:\n",
        "        raw = \"\\n\".join([f\"- {it.role}: {it.text}\" for it in items])\n",
        "        raw = _safe_clip(raw, 3500)\n",
        "        prompt = (\n",
        "            \"Summarize the following notes into a compact memory that preserves decisions, preferences, facts, and tasks. \"\n",
        "            f\"Keep it under {max_chars} characters.\\n\\nNOTES:\\n{raw}\\n\\nCOMPACT MEMORY:\"\n",
        "        )\n",
        "        summ = self._gen(prompt, max_new_tokens=170).strip()\n",
        "        if len(summ) > max_chars:\n",
        "            summ = summ[:max_chars].rstrip() + \"…\"\n",
        "        return summ\n",
        "\n",
        "    def consolidate(self) -> Optional[str]:\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cur = conn.cursor()\n",
        "        cur.execute(\"SELECT mid, role, text, created_ts, importance, tokens_est, meta_json FROM memories ORDER BY created_ts DESC LIMIT 160\")\n",
        "        rows = cur.fetchall()\n",
        "        conn.close()\n",
        "\n",
        "        items = []\n",
        "        for r in rows:\n",
        "            try:\n",
        "                meta = json.loads(r[6]) if r[6] else {}\n",
        "            except Exception:\n",
        "                meta = {}\n",
        "            items.append(MemoryItem(r[0], r[1], r[2], int(r[3]), float(r[4]), int(r[5]), meta))\n",
        "\n",
        "        if not items:\n",
        "            return None\n",
        "\n",
        "        items_sorted = sorted(items, key=lambda x: (-(x.importance + 0.15 * (1.0 / (1.0 + (_now_ts() - x.created_ts) / 3600.0))), -x.created_ts))\n",
        "        picked = items_sorted[:18]\n",
        "        summary = self._compress_memories(picked, max_chars=520)\n",
        "\n",
        "        cid = f\"c:{_sha(f'{_now_ts()}::{summary[:120]}::{np.random.randint(0, 10**9)}')}\"\n",
        "        source_mids = [it.mid for it in picked]\n",
        "\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cur = conn.cursor()\n",
        "        cur.execute(\n",
        "            \"INSERT OR REPLACE INTO consolidations (cid, created_ts, summary, source_mids_json) VALUES (?, ?, ?, ?)\",\n",
        "            (cid, _now_ts(), summary, json.dumps(source_mids, ensure_ascii=False)),\n",
        "        )\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "        self.add_memory(\n",
        "            role=\"system\",\n",
        "            text=f\"Consolidated memory: {summary}\",\n",
        "            meta={\"signal\": \"consolidation\", \"pinned\": True, \"source_mids\": source_mids, \"cid\": cid, \"importance\": 0.95},\n",
        "        )\n",
        "        return cid"
      ],
      "metadata": {
        "id": "QXmY1fWBZjmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def _should_consolidate(self) -> bool:\n",
        "        if self.turns > 0 and self.turns % self.consolidate_every == 0:\n",
        "            return True\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cur = conn.cursor()\n",
        "        cur.execute(\"SELECT SUM(tokens_est) FROM memories\")\n",
        "        s = cur.fetchone()[0]\n",
        "        conn.close()\n",
        "        s = int(s or 0)\n",
        "        return s >= self.consolidate_trigger_tokens\n",
        "\n",
        "    def chat(self, user_text: str, user_meta: Optional[Dict[str, Any]] = None, max_answer_tokens: int = 220) -> Dict[str, Any]:\n",
        "        user_meta = user_meta or {}\n",
        "        self.turns += 1\n",
        "\n",
        "        self.stm.append({\"role\": \"user\", \"content\": user_text})\n",
        "        self.stm = self.stm[-(self.stm_max_turns * 2):]\n",
        "        self.add_memory(\"user\", user_text, meta=user_meta)\n",
        "\n",
        "        ltm = self.retrieve_ltm(user_text, topk=self.ltm_topk)\n",
        "        stm_block = self._format_stm()\n",
        "        ltm_block = self._format_ltm(ltm)\n",
        "\n",
        "        sys_rules = (\n",
        "            \"You are an AI agent with persistent memory. Use retrieved long-term memories to stay consistent. \"\n",
        "            \"If a memory conflicts with the user, ask a short clarifying question. Keep answers practical.\"\n",
        "        )\n",
        "\n",
        "        prompt = (\n",
        "            f\"{sys_rules}\\n\\n\"\n",
        "            f\"SHORT-TERM CONTEXT:\\n{_safe_clip(stm_block, 1800)}\\n\\n\"\n",
        "            f\"RETRIEVED LONG-TERM MEMORIES:\\n{ltm_block if ltm_block else '(none)'}\\n\\n\"\n",
        "            f\"USER REQUEST:\\n{user_text}\\n\\n\"\n",
        "            f\"ANSWER:\"\n",
        "        )\n",
        "        answer = self._gen(prompt, max_new_tokens=max_answer_tokens)\n",
        "\n",
        "        self.stm.append({\"role\": \"assistant\", \"content\": answer})\n",
        "        self.stm = self.stm[-(self.stm_max_turns * 2):]\n",
        "        self.add_memory(\"assistant\", answer, meta={\"signal\": \"response\"})\n",
        "\n",
        "        consolidation_id = None\n",
        "        if self._should_consolidate():\n",
        "            consolidation_id = self.consolidate()\n",
        "\n",
        "        return {\n",
        "            \"answer\": answer,\n",
        "            \"retrieved_ltm\": [\n",
        "                {\"mid\": it.mid, \"role\": it.role, \"importance\": it.importance, \"meta\": it.meta, \"text\": _safe_clip(it.text, 320)}\n",
        "                for it in ltm\n",
        "            ],\n",
        "            \"consolidation_id\": consolidation_id,\n",
        "        }\n",
        "\n",
        "    def inspect_recent_memories(self, n: int = 12) -> List[Dict[str, Any]]:\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cur = conn.cursor()\n",
        "        cur.execute(\"SELECT mid, role, text, created_ts, importance, tokens_est, meta_json FROM memories ORDER BY created_ts DESC LIMIT ?\", (n,))\n",
        "        rows = cur.fetchall()\n",
        "        conn.close()\n",
        "        out = []\n",
        "        for r in rows:\n",
        "            try:\n",
        "                meta = json.loads(r[6]) if r[6] else {}\n",
        "            except Exception:\n",
        "                meta = {}\n",
        "            out.append({\"mid\": r[0], \"role\": r[1], \"created_ts\": int(r[3]), \"importance\": float(r[4]), \"tokens_est\": int(r[5]), \"meta\": meta, \"text\": _safe_clip(r[2], 520)})\n",
        "        return out\n",
        "\n",
        "    def inspect_consolidations(self, n: int = 5) -> List[Dict[str, Any]]:\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cur = conn.cursor()\n",
        "        cur.execute(\"SELECT cid, created_ts, summary, source_mids_json FROM consolidations ORDER BY created_ts DESC LIMIT ?\", (n,))\n",
        "        rows = cur.fetchall()\n",
        "        conn.close()\n",
        "        out = []\n",
        "        for r in rows:\n",
        "            try:\n",
        "                src = json.loads(r[3]) if r[3] else []\n",
        "            except Exception:\n",
        "                src = []\n",
        "            out.append({\"cid\": r[0], \"created_ts\": int(r[1]), \"summary\": r[2], \"source_mids\": src})\n",
        "        return out"
      ],
      "metadata": {
        "id": "kLMjywZIZjlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762,
          "referenced_widgets": [
            "db2d831db42f4a1095af8529509e797e",
            "447480f32e134c59aad2982332914df8",
            "e506ecea9e304da7917e8632651a9109",
            "7b4e454a13f442b3b5b256b802ede7f7",
            "6bc914c995f141f285575457ae8470a1",
            "522a59e492de4c7fafb3748bb8057d37",
            "d67486a04d1b426eab076b027df9a2fd",
            "a18f5f1ed225471bb207585ba08e8dd0",
            "a9ac77293b9b44ecbda4692a6ea0d91a",
            "caf8e0d810ae4759a3c248d087563f8b",
            "d031516a6fa947818ced7eb3add92328",
            "07b6a4d101da40d0ae34901f6d5ab51f",
            "6b67475766d94c2a8d96bfbe4fb50410",
            "9da7897f19204f168776f0f8245019c7",
            "58be584b67384fbe8d809be43f8ac7c7",
            "42879b69ef194448a5ddd1f865612383",
            "42e8ae2a44804734bb62b76688148f9b",
            "e144c36b294748e4ad79af54ff43d444",
            "ae51cc5faa4046f3bf04cef1b7abdbba",
            "3af6adf8891c4ce4878f2a74bdb71b09",
            "3955ecec59ea415c83fa0f5b11e41edc",
            "633cb1bbd0384a5687b61a5f592af84b"
          ]
        },
        "id": "AIfbjbrZ4ru7",
        "outputId": "918d3776-395d-471f-ed08-a1bf64151131"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db2d831db42f4a1095af8529509e797e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/190 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07b6a4d101da40d0ae34901f6d5ab51f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tied weights mapping and config for this model specifies to tie shared.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "USER: I prefer answers in bullet points and I’m working on a Colab tutorial.\n",
            "ASSISTANT: are you using the Colab tutorial?\n",
            "RETRIEVED_LTM: [(1.0, 'I prefer answers in bullet points and I’m working on a Colab tutorial.')]\n",
            "\n",
            "USER: Remember that my project is about an EverMem-style agent OS with FAISS + SQLite.\n",
            "ASSISTANT: answer: yes\n",
            "RETRIEVED_LTM: [(1.0, 'Remember that my project is about an EverMem-style agent OS with FAISS + SQLite.'), (1.0, 'I prefer answers in bullet points and I’m working on a Colab tutorial.'), (0.6163180262308081, 'are you using the Colab tutorial?')]\n",
            "\n",
            "USER: Give me a 5-step plan to add memory importance scoring and consolidation.\n",
            "ASSISTANT: yes\n",
            "RETRIEVED_LTM: [(0.8752032546602084, 'Give me a 5-step plan to add memory importance scoring and consolidation.'), (1.0, 'I prefer answers in bullet points and I’m working on a Colab tutorial.'), (1.0, 'Remember that my project is about an EverMem-style agent OS with FAISS + SQLite.')]\n",
            "\n",
            "USER: Now remind me what you know about my preferences and project, briefly.\n",
            "ASSISTANT: yes\n",
            "RETRIEVED_LTM: [(0.8231339938520656, 'Now remind me what you know about my preferences and project, briefly.'), (0.8752032546602084, 'Give me a 5-step plan to add memory importance scoring and consolidation.'), (1.0, 'Remember that my project is about an EverMem-style agent OS with FAISS + SQLite.')]\n",
            "\n",
            "RECENT MEMORIES:\n",
            "assistant 0.44931471805599454 yes\n",
            "assistant 0.44931471805599454 yes\n",
            "user 0.8231339938520656 Now remind me what you know about my preferences and project, briefly.\n",
            "assistant 0.5042453324894 answer: yes\n",
            "user 0.8752032546602084 Give me a 5-step plan to add memory importance scoring and consolidation.\n",
            "assistant 0.6163180262308081 are you using the Colab tutorial?\n",
            "user 1.0 Remember that my project is about an EverMem-style agent OS with FAISS + SQLite.\n",
            "user 1.0 I prefer answers in bullet points and I’m working on a Colab tutorial.\n",
            "\n",
            "RECENT CONSOLIDATIONS:\n"
          ]
        }
      ],
      "source": [
        "agent = EverMemAgentOS()\n",
        "\n",
        "agent.upsert_kv(\"profile\", {\"name\": \"User\", \"preferences\": {\"style\": \"concise\"}})\n",
        "\n",
        "demo_queries = [\n",
        "    (\"I prefer answers in bullet points and I’m working on a Colab tutorial.\", {\"signal\": \"preference\", \"pinned\": True}),\n",
        "    (\"Remember that my project is about an EverMem-style agent OS with FAISS + SQLite.\", {\"signal\": \"fact\", \"pinned\": True}),\n",
        "    (\"Give me a 5-step plan to add memory importance scoring and consolidation.\", {\"signal\": \"task\"}),\n",
        "    (\"Now remind me what you know about my preferences and project, briefly.\", {\"signal\": \"task\"}),\n",
        "]\n",
        "\n",
        "for q, meta in demo_queries:\n",
        "    r = agent.chat(q, user_meta=meta, max_answer_tokens=180)\n",
        "    print(\"\\nUSER:\", q)\n",
        "    print(\"ASSISTANT:\", r[\"answer\"])\n",
        "    if r[\"retrieved_ltm\"]:\n",
        "        print(\"RETRIEVED_LTM:\", [(x[\"importance\"], x[\"text\"]) for x in r[\"retrieved_ltm\"][:3]])\n",
        "    if r[\"consolidation_id\"]:\n",
        "        print(\"CONSOLIDATED:\", r[\"consolidation_id\"])\n",
        "\n",
        "print(\"\\nRECENT MEMORIES:\")\n",
        "for m in agent.inspect_recent_memories(10):\n",
        "    print(m[\"role\"], m[\"importance\"], m[\"text\"])\n",
        "\n",
        "print(\"\\nRECENT CONSOLIDATIONS:\")\n",
        "for c in agent.inspect_consolidations(3):\n",
        "    print(c[\"cid\"], c[\"summary\"])"
      ]
    }
  ]
}